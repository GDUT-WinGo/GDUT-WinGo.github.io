<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Kafka | Wingo&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Kafka">
    <meta name="description" content="Kafka 基本介绍及简单使用。">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="http://yoursite.com/2020/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE/Kafka/index.html">
<meta property="og:site_name" content="Wingo&#39;s Blog">
<meta property="og:description" content="Kafka 基本介绍及简单使用。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka01.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka02.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka03.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka04.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka05.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka06.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka07.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka08.png">
<meta property="article:published_time" content="2020-05-06T04:05:51.000Z">
<meta property="article:modified_time" content="2020-07-10T03:41:01.609Z">
<meta property="article:author" content="Wingo">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka01.png">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Wingo</h5>
          <a href="mailto:1318263468@qq.com" title="1318263468@qq.com" class="mail">1318263468@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Kafka</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Kafka</h1>
        <h5 class="subtitle">
            
                <time datetime="2020-05-06T04:05:51.000Z" itemprop="datePublished" class="page-time">
  2020-05-06
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基本概念"><span class="post-toc-number">1.</span> <span class="post-toc-text">基本概念</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#基础架构"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">基础架构</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#安装部署"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">安装部署</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Shell-操作"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">Shell 操作</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#架构深入"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">架构深入</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#生产者"><span class="post-toc-number">2.</span> <span class="post-toc-text">生产者</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#分区策略"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">分区策略</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#可靠性"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">可靠性</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#ISR"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">ISR</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#应答机制"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">应答机制</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#故障处理"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">故障处理</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Exactly-Once"><span class="post-toc-number">2.6.</span> <span class="post-toc-text">Exactly Once</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#消费者"><span class="post-toc-number">3.</span> <span class="post-toc-text">消费者</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#分区分配策略"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">分区分配策略</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#offset-维护"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">offset 维护</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#事务"><span class="post-toc-number">4.</span> <span class="post-toc-text">事务</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Producer-API"><span class="post-toc-number">5.</span> <span class="post-toc-text">Producer API</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#消息发送流程"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">消息发送流程</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#异步发送"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">异步发送</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#同步发送"><span class="post-toc-number">5.3.</span> <span class="post-toc-text">同步发送</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Consumer-API"><span class="post-toc-number">6.</span> <span class="post-toc-text">Consumer API</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#自动提交"><span class="post-toc-number">6.1.</span> <span class="post-toc-text">自动提交</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#手动提交"><span class="post-toc-number">6.2.</span> <span class="post-toc-text">手动提交</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#自定义存储"><span class="post-toc-number">6.3.</span> <span class="post-toc-text">自定义存储</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#拦截器"><span class="post-toc-number">7.</span> <span class="post-toc-text">拦截器</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Kafka-Eagle"><span class="post-toc-number">8.</span> <span class="post-toc-text">Kafka Eagle</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#杂项"><span class="post-toc-number">9.</span> <span class="post-toc-text">杂项</span></a></li></ol>
        </nav>
    </aside>


<article id="post-大数据/Kafka"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Kafka</h1>
        <div class="post-meta">
            <time class="post-time" title="2020-05-06 12:05:51" datetime="2020-05-06T04:05:51.000Z"  itemprop="datePublished">2020-05-06</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>Kafka 基本介绍及简单使用。</p>
<a id="more"></a>

<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>Kafka 是一个分布式的基于发布 / 订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</p>
<p><strong>点对点模式</strong>（一对一，消费者主动拉取数据，消息收到后消息清除）</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka01.png" alt=""></p>
<p><strong>发布 / 订阅模式</strong>（一对多，消费者消费数据之后不会清除消息）</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka02.png" alt=""></p>
<h4 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h4><p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka03.png" alt=""></p>
<p>Producer：消息生产者，就是向 Kafka Broker 发消息的客户端。</p>
<p>Consumer：消息消费者，向 Kafka Broker 取消息的客户端。</p>
<p>Consumer Group：消费者组，由多个 Consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>Broker：一台 Kafka 服务器就是一个 Broker。一个集群由多个 Broker 组成。一个 Broker 可以容纳多个 Topic。</p>
<p>Topic：可以理解为一个队列，生产者和消费者面向的都是一个 Topic。</p>
<p>Partition：为了实现扩展性，一个非常大的 Topic 可以分布到多个 Broker（即服务器）上，一个 Topic 可以分为多个 Partition，每个 Partition 是一个有序的队列。</p>
<p>Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 Partition 数据不丢失，且 Kafka 仍然能够继续工作，Kafka 提供了副本机制，一个 Topic 的每个分区都有若干个副本，一个 Leader 和若干个 Follower。</p>
<p>Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</p>
<p>Follower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Follower。</p>
<h4 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.11-0.11.0.0.tgz -C /opt/module/</span><br><span class="line">mv kafka_2.11-0.11.0.0/ kafka</span><br><span class="line">mkdir logs</span><br><span class="line">cd config/</span><br><span class="line">vi server.properties</span><br><span class="line">    #broker 的全局唯一编号，不能重复</span><br><span class="line">    broker.id=0</span><br><span class="line">    #删除 topic 功能使能</span><br><span class="line">    delete.topic.enable=true</span><br><span class="line">    #处理网络请求的线程数量</span><br><span class="line">    num.network.threads=3</span><br><span class="line">    #用来处理磁盘 IO 的现成数量</span><br><span class="line">    num.io.threads=8</span><br><span class="line">    #发送套接字的缓冲区大小</span><br><span class="line">    socket.send.buffer.bytes=102400</span><br><span class="line">    #接收套接字的缓冲区大小</span><br><span class="line">    socket.receive.buffer.bytes=102400</span><br><span class="line">    #请求套接字的缓冲区大小</span><br><span class="line">    socket.request.max.bytes=104857600</span><br><span class="line">    #kafka 运行日志存放的路径</span><br><span class="line">    log.dirs=/opt/module/kafka/logs</span><br><span class="line">    #topic 在当前 broker 上的分区个数</span><br><span class="line">    num.partitions=1</span><br><span class="line">    #用来恢复和清理 data 下数据的线程数量</span><br><span class="line">    num.recovery.threads.per.data.dir=1</span><br><span class="line">    #segment 文件保留的最长时间，超时将被删除</span><br><span class="line">    log.retention.hours=168</span><br><span class="line">    #配置连接 Zookeeper 集群地址</span><br><span class="line">    zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181</span><br><span class="line">sudo vi /etc/profile</span><br><span class="line">    #KAFKA_HOME</span><br><span class="line">    export KAFKA_HOME=/opt/module/kafka</span><br><span class="line">    export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将配置分发到其它 Broker，并且记得修改其它 Broker 的环境变量</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其它 Broker 的 broker.id 记得修改，不得重复</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Kafka 群起脚本</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"========== <span class="variable">$i</span> =========="</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">'/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties'</span></span><br><span class="line">    <span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h4 id="Shell-操作"><a href="#Shell-操作" class="headerlink" title="Shell 操作"></a>Shell 操作</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 集群规划：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop102 位 kafka </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看当前服务器中的所有 topic</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper hadoop102:2181 --list</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 topic</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除 topic</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first</span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要 server.properties 中设置 delete.topic.enable=<span class="literal">true</span> 否则只是标记删除。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 发送消息</span></span><br><span class="line">bin/kafka-console-producer.sh --brokerlist hadoop102:9092 --topic first</span><br><span class="line"><span class="meta">#</span><span class="bash"> 消费消息</span></span><br><span class="line">bin/kafka-console-consumer.sh  --bootstrap-server hadoop102:9092 --topic first</span><br><span class="line"><span class="meta">#</span><span class="bash"> --from-beginning：会把主题中以往所有的数据都读取出来</span></span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个 Topic 的详情</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper hadoop102:2181 --describe --topic first</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改分区数</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper hadoop102:2181 --alter --topic first --partitions 6</span><br></pre></td></tr></table></figure>

<h4 id="架构深入"><a href="#架构深入" class="headerlink" title="架构深入"></a>架构深入</h4><p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka04.png" alt=""></p>
<p>Kafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic 的。 </p>
<p>topic 是逻辑上的概念，而 partition 是物理上的概念，每个 partition 对应于一个 log 文 件，该 log 文件中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费。</p>
<p>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位 效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。每个 segment 对应两个文件：“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic 名称+分区序号。</p>
<p>例如，first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka05.png" alt=""></p>
<p>index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log 文件的结构示意图。</p>
<p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</p>
<h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><h4 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h4><blockquote>
<p>方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic 又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；</p>
<p>可以提高并发，因为可以以 Partition 为单位读写了。</p>
</blockquote>
<p>将 producer 发送的数据封装成一个 ProducerRecord 对象。</p>
<ul>
<li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</li>
<li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</li>
<li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</li>
</ul>
<h4 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h4><p>为保证 producer 发送的数据，能可靠的发送到指定的 topic，topic 的每个 partition 收到 producer 发送的数据后，都需要向 producer 发送 ack（acknowledgement 确认收到），如果 producer 收到 ack，就会进行下一轮的发送，否则重新发送数据。</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka06.png" alt=""></p>
<p>Kafka 选择了第二种方案，原因如下：</p>
<ul>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1 个副本，而 Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</li>
</ul>
<h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4><p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据， 但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去， 直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p>
<p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集 合。当 ISR 中的 follower 完成数据的同步之后，follower 就会给 fleader 发送 ack。如果 follower 长时间未向 leader 同步数据 ， 则该 follower 将被踢出 ISR ， 该时间阈值由 replica.lag.time.max.ms 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p>
<h4 id="应答机制"><a href="#应答机制" class="headerlink" title="应答机制"></a>应答机制</h4><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失， 所以没必要等 ISR 中的 follower 全部接收成功。 所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡， 选择以下的配置。</p>
<p>acks 为 0： producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟，broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据；</p>
<p>acks 为 1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据；</p>
<p>acks 为 -1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower 全部落盘成功后才 返回 ack。但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。</p>
<h4 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h4><p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka07.png" alt=""></p>
<p>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</p>
<p><strong>follower 故障</strong></p>
<p>follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重新加入 ISR 了。</p>
<p><strong>leader 故障</strong></p>
<p>leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader 同步数据。这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
<blockquote>
<p>将服务器的 ACK 级别设置为 -1，可以保证 Producer 到 Server 之间不会丢失数据，但不能保证数据不重复，即 At Least Once 语义。</p>
<p>将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被发送一次，但不能保证数据不丢失，即 At Most Once 语义。</p>
</blockquote>
<h4 id="Exactly-Once"><a href="#Exactly-Once" class="headerlink" title="Exactly Once"></a>Exactly Once</h4><p>0.11 版本的 Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指 Producer 不论 向 Server 发送多少次重复数据，Server 端都只会持久化一条。幂等性结合 At Least Once 语 义，就构成了 Kafka 的 Exactly Once 语义。</p>
<p>要启用幂等性，只需要将 Producer 的参数中 enable.idompotence 设置为 true 即可。Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在 初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而 Broker 端会对做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。 </p>
<p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以幂等性无法保证跨分区跨会话的 Exactly Once。</p>
<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><p>consumer 采用 pull（拉）模式从 broker 中读取数据。</p>
<p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。 它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。</p>
<p>pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有数据可供消费，consumer 会等待一段时间之后再消费，这段时长即为 timeout。</p>
<h4 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h4><p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。 Kafka 有两种分配策略，一是 RoundRobin，一是 Range。</p>
<h4 id="offset-维护"><a href="#offset-维护" class="headerlink" title="offset 维护"></a>offset 维护</h4><p>由于 consumer 在消费过程中可能会出现断电宕机等故障，consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢复后继续消费。</p>
<p>Kafka 0.9 版本之前，consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始， consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic 为 __consumer_offsets。</p>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p><strong>Kafka 事务</strong></p>
<p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<p><strong>Producer 事务</strong></p>
<p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer 获得的 PID 和 Transaction ID 绑定。这样当 Producer 重启后就可以通过正在进行的 Transaction ID 获得原来的 PID。 为了管理 Transaction，Kafka 引入了一个新的组件 Transaction Coordinator。Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于 事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p>
<h3 id="Producer-API"><a href="#Producer-API" class="headerlink" title="Producer API"></a>Producer API</h3><h4 id="消息发送流程"><a href="#消息发送流程" class="headerlink" title="消息发送流程"></a>消息发送流程</h4><p>Kafka 的 Producer 发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程：main 线程和 Sender 线程，以及一个线程共享变量：RecordAccumulator。 main 线程将消息发送给 RecordAccumulator，Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka broker。</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Kafka/Kafka08.png" alt=""></p>
<p><strong>相关参数</strong></p>
<p>batch.size：只有数据积累到 batch.size 之后，sender 才会发送数据。<br>linger.ms：如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。</p>
<h4 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a>异步发送</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.11.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>常用类</strong></p>
<blockquote>
<p>KafkaProducer：需要创建一个生产者对象，用来发送数据；<br>ProducerConfig：获取所需的一系列配置参数；<br>ProducerRecord：每条数据都要封装成一个 ProducerRecord 对象。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 不带回调函数的 API</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// kafka 集群，broker-list</span></span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">        <span class="comment">// 重试次数</span></span><br><span class="line">        props.put(<span class="string">"retries"</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 批次大小</span></span><br><span class="line">        props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);</span><br><span class="line">        <span class="comment">// 等待时间</span></span><br><span class="line">        props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// RecordAccumulator 缓冲区大小</span></span><br><span class="line">        props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            producer.send(</span><br><span class="line">                <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(</span><br><span class="line">                    <span class="string">"first"</span>, Integer.toString(i), Integer.toString(i) <span class="comment">// 组 key value</span></span><br><span class="line">                )</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是 RecordMetadata 和 Exception，如果 Exception 为 null，说明消息发送成功，如果 Exception 不为 null，说明消息发送失败。</p>
<p>消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 带回调函数的 API</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 常规配置</span></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            producer.send(</span><br><span class="line">                <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(</span><br><span class="line">                    <span class="string">"first"</span>, Integer.toString(i), Integer.toString(i)</span><br><span class="line">                ), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                    <span class="comment">// 回调函数，该方法会在 Producer 收到 ack 时调用，为异步调用</span></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">                            System.out.println(<span class="string">"success-&gt;"</span> + metadata.offset());</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            exception.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="同步发送"><a href="#同步发送" class="headerlink" title="同步发送"></a>同步发送</h4><p>同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回 ack。 </p>
<p>由于 send 方法返回的是一个 Future 对象，根据 Futrue 对象的特点也可以实现同步发送的效果，只需在调用 Future 对象的 get 方发即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">		<span class="comment">// 常规配置</span></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            producer.send(</span><br><span class="line">                <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(</span><br><span class="line">                    <span class="string">"first"</span>, Integer.toString(i), Integer.toString(i)</span><br><span class="line">                )</span><br><span class="line">            ).get(); <span class="comment">// 阻塞等待获取返回值</span></span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Consumer-API"><a href="#Consumer-API" class="headerlink" title="Consumer API"></a>Consumer API</h3><p>consumer 消费数据时的可靠性是很容易保证的，因为数据在 Kafka 中是持久化的，故不用担心数据丢失问题。</p>
<p>由于 consumer 在消费过程中可能会出现断电宕机等故障，consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢复后继续消费。 所以 offset 的维护是 consumer 消费数据是必须考虑的问题。</p>
<p>为了使我们能够专注于自己的业务逻辑，Kafka 提供了自动提交 offset 的功能。 自动提交 offset 的相关参数： </p>
<blockquote>
<p>enable.auto.commit：是否开启自动提交 offset 功能；<br>auto.commit.interval.ms：自动提交 offset 的时间间隔。</p>
</blockquote>
<h4 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.11.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>);</span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">        props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>);</span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(</span><br><span class="line">                    <span class="string">"offset = %d, key = %s, value = %s%n"</span>, </span><br><span class="line">                    record.offset(), record.key(), record.value()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h4><blockquote>
<p>自动提交是基于时间提交的，开发人员难以把握 offset 提交的时机。因此 Kafka 还提供了手动提交 offset 的 API。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 同步提交</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomComsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// Kafka 集群</span></span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        <span class="comment">// 消费者组，只要 group.id 相同，就属于同一个消费者组</span></span><br><span class="line">        props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>);</span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>); <span class="comment">// 关闭自动提交 offset</span></span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>)); <span class="comment">// 消费者订阅主题</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 消费者拉取数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(</span><br><span class="line">                    <span class="string">"offset = %d, key = %s, value = %s%n"</span>, </span><br><span class="line">                    record.offset(), record.key(), record.value()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 同步提交，当前线程会阻塞直到 offset 提交成功</span></span><br><span class="line">            consumer.commitSync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 异步提交</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomComsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// ... 常规配置</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>)); <span class="comment">// 消费者订阅主题</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 消费者拉取数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(</span><br><span class="line">                    <span class="string">"offset = %d, key = %s, value = %s%n"</span>, </span><br><span class="line">                    record.offset(), record.key(), record.value()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//异步提交</span></span><br><span class="line">            consumer.commitAsync(<span class="keyword">new</span> OffsetCommitCallback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">                    Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        System.err.println(<span class="string">"Commit failed for"</span> + offsets);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="自定义存储"><a href="#自定义存储" class="headerlink" title="自定义存储"></a>自定义存储</h4><p>Kafka 0.9 版本之前，offset 存储在 zookeeper，0.9 版本及之后，默认将 offset 存储在 Kafka 的一个内置的 topic 中。除此之外，Kafka 还可以选择自定义存储 offset。 offset 的维护是相当繁琐的，因为需要考虑到消费者的 Rebalance。 </p>
<p>当有新的消费者加入消费者组、已有的消费者推出消费者组或者所订阅的主题的分区发生变化，就会触发到分区的重新分配，重新分配的过程叫做 Rebalance。 </p>
<p>消费者发生 Rebalance 之后，每个消费者消费的分区就会发生变化。因此消费者要首先获取到自己被重新分配到的分区，并且定位到每个分区最近提交的 offset 位置继续消费。 </p>
<p>要实现自定义存储 offset，需要借助 ConsumerRebalanceListener，以下为示例代码，其中提交和获取 offset 的方法，需要根据所选的 offset 存储系统自行实现。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 自定义存储 offset 的容器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;TopicPartition, Long&gt; currentOffset = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建配置信息</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// Kafka 集群</span></span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        <span class="comment">// 消费者组，只要 group.id 相同，就属于同一个消费者组</span></span><br><span class="line">        props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>);</span><br><span class="line">        <span class="comment">// 关闭自动提交 offset</span></span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);</span><br><span class="line">        <span class="comment">// Key 和 Value 的反序列化类</span></span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        <span class="comment">// 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        <span class="comment">//消费者订阅主题</span></span><br><span class="line">        consumer.subscribe(</span><br><span class="line">            Arrays.asList(<span class="string">"first"</span>), </span><br><span class="line">            <span class="keyword">new</span> ConsumerRebalanceListener() &#123;</span><br><span class="line">                <span class="comment">// 该方法会在 Rebalance 之前调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">                    commitOffset(currentOffset);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 该方法会在 Rebalance 之后调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">                    currentOffset.clear();</span><br><span class="line">                    <span class="keyword">for</span> (TopicPartition partition : partitions) &#123;</span><br><span class="line">                        <span class="comment">// 定位到最近提交的 offset 位置继续消费</span></span><br><span class="line">                        consumer.seek(partition, getOffset(partition));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>); <span class="comment">//消费者拉取数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(</span><br><span class="line">                    <span class="string">"offset = %d, key = %s, value = %s%n"</span>, </span><br><span class="line">                    record.offset(), record.key(), record.value()</span><br><span class="line">                );</span><br><span class="line">                currentOffset.put(</span><br><span class="line">                    <span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), record.offset()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">            commitOffset(currentOffset); <span class="comment">// 异步提交</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 获取某分区的最新 offset</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getOffset</span><span class="params">(TopicPartition partition)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 提交该消费者所有分区的 offset</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">commitOffset</span><span class="params">(Map&lt;TopicPartition, Long&gt; currentOffset)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h3><p>producer 拦截器（interceptor）是在 Kafka 0.10 版本被引入的，主要用于实现 clients 端的定制化控制逻辑。 对于 producer 而言，interceptor 使得用户在消息发送前以及 producer 回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。</p>
<p>同时，producer 允许用户指定多个 interceptor 按序作用于同一条消息从而形成一个拦截链（interceptor chain）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 增加时间戳拦截器</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 获取配置信息和初始化数据时调用</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 对消息进行自定义操作</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建一个新的 record，把时间戳写入消息体的最前部</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ProducerRecord(record.topic(), record.partition(), </span><br><span class="line">                                  record.timestamp(), record.key(),</span><br><span class="line">                                  System.currentTimeMillis() + <span class="string">","</span> + record.value().toString());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 统计发送消息成功和发送失败消息数，并在 producer 关闭时打印这两个计数器</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CounterInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> errorCounter = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> successCounter = <span class="number">0</span>;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> record;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 消息发送成功或者失败后都会调用此方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 统计成功和失败的次数</span></span><br><span class="line">        <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">            successCounter++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            errorCounter++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 保存结果</span></span><br><span class="line">        System.out.println(<span class="string">"Successful sent: "</span> + successCounter);</span><br><span class="line">        System.out.println(<span class="string">"Failed sent: "</span> + errorCounter);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// producer </span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterceptorProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 设置配置信息</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">        props.put(<span class="string">"retries"</span>, <span class="number">3</span>);</span><br><span class="line">        props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);</span><br><span class="line">        props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line">        props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="comment">// 构建拦截链</span></span><br><span class="line">        List&lt;String&gt; interceptors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        interceptors.add(<span class="string">"com.wingo.kafka.interceptor.TimeInterceptor"</span>);</span><br><span class="line">        interceptors.add(<span class="string">"com.wingo.kafka.interceptor.CounterInterceptor"</span>);</span><br><span class="line">        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br><span class="line">        String topic = <span class="string">"first"</span>;</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="comment">// 发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="string">"message"</span> + i);</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 一定要关闭 producer，这样才会调用 interceptor 的 close 方法</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Kafka-Eagle"><a href="#Kafka-Eagle" class="headerlink" title="Kafka Eagle"></a>Kafka Eagle</h3><blockquote>
<p>基于 Web 的 Kafka 监控。</p>
</blockquote>
<h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><p><strong>高效读写数据</strong></p>
<p>Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端， 为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这 磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p>零拷贝。</p>
<p><strong>Zookeeper 的作用</strong></p>
<p>Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作。 Controller 的管理工作都是依赖于 Zookeeper 的。</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2020-07-10T03:41:01.609Z" itemprop="dateUpdated">2020-07-10 11:41:01</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="Wingo">
            Wingo
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flume/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">Flume</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2020/05/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/HBase/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Hbase</h4>
      </a>
    </div>
  
</nav>



    




















</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
            <span>得失从缘，心无增减</span>
        </p>
    </div> 
    <div class="bottom">
        <p><span>Wingo &copy; 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: false, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










</body>
</html>
