<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Flume | Wingo&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Flume">
    <meta name="description" content="Flume 基本介绍及简单使用。">
<meta property="og:type" content="article">
<meta property="og:title" content="Flume">
<meta property="og:url" content="http://yoursite.com/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flume/index.html">
<meta property="og:site_name" content="Wingo&#39;s Blog">
<meta property="og:description" content="Flume 基本介绍及简单使用。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume01.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume02.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume03.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume04.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume05.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume06.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume07.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume08.png">
<meta property="article:published_time" content="2020-05-08T06:27:33.000Z">
<meta property="article:modified_time" content="2020-07-10T03:37:23.451Z">
<meta property="article:author" content="Wingo">
<meta property="article:tag" content="Flume">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume01.png">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Wingo</h5>
          <a href="mailto:1318263468@qq.com" title="1318263468@qq.com" class="mail">1318263468@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Flume</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Flume</h1>
        <h5 class="subtitle">
            
                <time datetime="2020-05-08T06:27:33.000Z" itemprop="datePublished" class="page-time">
  2020-05-08
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基本概念"><span class="post-toc-number">1.</span> <span class="post-toc-text">基本概念</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#快速入门"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">快速入门</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#实际案例"><span class="post-toc-number">2.</span> <span class="post-toc-text">实际案例</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Exec"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">Exec</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Spooldir"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">Spooldir</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Taildir"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">Taildir</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#进阶特性"><span class="post-toc-number">3.</span> <span class="post-toc-text">进阶特性</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#事务"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">事务</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#内部原理"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">内部原理</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#拓扑结构"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">拓扑结构</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#企业开发"><span class="post-toc-number">4.</span> <span class="post-toc-text">企业开发</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#复制和复用"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">复制和复用</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#均衡和转移"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">均衡和转移</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#聚合"><span class="post-toc-number">4.3.</span> <span class="post-toc-text">聚合</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Interceptor"><span class="post-toc-number">4.4.</span> <span class="post-toc-text">Interceptor</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Source"><span class="post-toc-number">4.5.</span> <span class="post-toc-text">Source</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Sink"><span class="post-toc-number">4.6.</span> <span class="post-toc-text">Sink</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Ganglia-监控"><span class="post-toc-number">5.</span> <span class="post-toc-text">Ganglia 监控</span></a></li></ol>
        </nav>
    </aside>


<article id="post-大数据/Flume"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Flume</h1>
        <div class="post-meta">
            <time class="post-time" title="2020-05-08 14:27:33" datetime="2020-05-08T06:27:33.000Z"  itemprop="datePublished">2020-05-08</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>Flume 基本介绍及简单使用。</p>
<a id="more"></a>

<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume 基于流式架构，灵活简单。</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume01.png" alt=""></p>
<p>Flume 最主要的作用就是，实时读取服务器本地磁盘的数据，将数据写入到 HDFS。</p>
<p><strong>基础框架</strong></p>
<p>Flume 支持将事件流向一个或者多个目的地，这种模式可以将相同数据复制到多个 channel 中，或者将不同数据分发到不同的 channel 中，sink 可以选择传送到不同的目的地。</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume02.png" alt=""></p>
<p> <strong>Agent</strong></p>
<p>Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。 Agent 主要有 3 个部分组成：Source、Channel、Sink。</p>
<p> <strong>Source</strong></p>
<p>Source 是负责接收数据到 Flume Agent 的组件。Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy。</p>
<p><strong>Sink</strong></p>
<p>Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent。 Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。</p>
<p><strong>Channel</strong></p>
<p>Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个 Sink 的读取操作。 </p>
<p>Flume 自带两种 Channel：Memory Channel 和 File Channel。</p>
<blockquote>
<p>Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适 用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。 </p>
<p>File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p>
</blockquote>
<p> <strong>Event</strong></p>
<p>传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。 Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构， Body 用来存放该条数据，形式为字节数组。</p>
<h4 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf apache-flume-1.7.0-bin.tar.gz -C /opt/module/</span><br><span class="line">mv apache-flume-1.7.0-bin flume</span><br><span class="line">mv flume-env.sh.template flume-env.sh</span><br><span class="line">vi flume-env.sh</span><br><span class="line"><span class="meta">	#</span><span class="bash"> <span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>使用 Flume 监听一个端口，收集该端口数据（使用 nectcat 工具向该端口发送数据），并打印到控制台。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装 netcat 工具</span></span><br><span class="line">sudo yum install -y nc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 判断 44444 端口是否被占用 </span></span><br><span class="line">sudo netstat -tunlp | grep 44444</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 Flume Agent 配置文件 flume-netcat-logger.conf </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 flume 目录下创建 job 文件夹并进入 job 文件夹。</span></span><br><span class="line">mkdir job</span><br><span class="line">cd job/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 job 文件夹下创建 Flume Agent 配置文件 flume-netcat-logger.conf。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vim flume-netcat-logger.conf</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 flume-netcat-logger.conf 文件中添加如下内容。（参考官方文档配置）</span></span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a1.sources = r1</span><br><span class="line">    a1.sinks = k1</span><br><span class="line">    a1.channels = c1</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a1.sources.r1.type = netcat # 数据来源 netcat 工具</span><br><span class="line">    a1.sources.r1.bind = localhost</span><br><span class="line">    a1.sources.r1.port = 44444</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a1.sinks.k1.type = logger # 数据输出目的地为 logger 控制台类型</span><br><span class="line">    # Use a channel which buffers events in memory</span><br><span class="line">    a1.channels.c1.type = memory # 通道的存储为内存型</span><br><span class="line">    a1.channels.c1.capacity = 1000</span><br><span class="line">    a1.channels.c1.transactionCapacity = 100 # 100 条 even 后才提交事务</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a1.sources.r1.channels = c1</span><br><span class="line">    a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启 flume 监听端口 控制台日志打印级别设置为 INFO 级别</span></span><br><span class="line">bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 netcat 工具向本机的 44444 端口发送内容</span></span><br><span class="line"> nc localhost 44444</span><br></pre></td></tr></table></figure>

<h3 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h3><h4 id="Exec"><a href="#Exec" class="headerlink" title="Exec"></a>Exec</h4><blockquote>
<p>实时监控 Hive 日志，并上传到 HDFS 中。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Flume 要想将数据输出到 HDFS，须持有 Hadoop 相关 jar 包</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 flume-file-hdfs.conf 文件</span></span><br><span class="line"> vim flume-file-hdfs.conf</span><br><span class="line">     # Name the components on this agent</span><br><span class="line">    a2.sources = r2</span><br><span class="line">    a2.sinks = k2</span><br><span class="line">    a2.channels = c2</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a2.sources.r2.type = exec</span><br><span class="line">    a2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log</span><br><span class="line">    a2.sources.r2.shell = /bin/bash -c</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a2.sinks.k2.type = hdfs</span><br><span class="line">    a2.sinks.k2.hdfs.path = hdfs://hadoop102:9000/flume/%Y%m%d/%H</span><br><span class="line">    # 上传文件的前缀</span><br><span class="line">    a2.sinks.k2.hdfs.filePrefix = logs-</span><br><span class="line">    # 是否按照时间滚动文件夹</span><br><span class="line">    a2.sinks.k2.hdfs.round = true</span><br><span class="line">    # 多少时间单位创建一个新的文件夹</span><br><span class="line">    a2.sinks.k2.hdfs.roundValue = 1</span><br><span class="line">    # 重新定义时间单位</span><br><span class="line">    a2.sinks.k2.hdfs.roundUnit = hour</span><br><span class="line">    # 是否使用本地时间戳</span><br><span class="line">    a2.sinks.k2.hdfs.useLocalTimeStamp = true</span><br><span class="line">    # 积攒多少个 Event 才 flush 到 HDFS 一次</span><br><span class="line">    a2.sinks.k2.hdfs.batchSize = 1000</span><br><span class="line">    # 设置文件类型，可支持压缩</span><br><span class="line">    a2.sinks.k2.hdfs.fileType = DataStream</span><br><span class="line">    # 多久生成一个新的文件</span><br><span class="line">    a2.sinks.k2.hdfs.rollInterval = 30</span><br><span class="line">    # 设置每个文件的滚动大小</span><br><span class="line">    a2.sinks.k2.hdfs.rollSize = 134217700</span><br><span class="line">    # 文件的滚动与 Event 数量无关</span><br><span class="line">    a2.sinks.k2.hdfs.rollCount = 0</span><br><span class="line">    # Use a channel which buffers events in memory</span><br><span class="line">    a2.channels.c2.type = memory</span><br><span class="line">    a2.channels.c2.capacity = 1000</span><br><span class="line">    a2.channels.c2.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a2.sources.r2.channels = c2</span><br><span class="line">    a2.sinks.k2.channel = c2</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a2 --conf-file job/flume-file-hdfs.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启 Hadoop 和 Hive 并操作 Hive 产生日志</span></span><br></pre></td></tr></table></figure>

<h4 id="Spooldir"><a href="#Spooldir" class="headerlink" title="Spooldir"></a>Spooldir</h4><blockquote>
<p>使用 Flume 监听整个目录的文件，并上传至 HDFS。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">vim flume-dir-hdfs.conf</span><br><span class="line">    a3.sources = r3</span><br><span class="line">    a3.sinks = k3</span><br><span class="line">    a3.channels = c3</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a3.sources.r3.type = spooldir</span><br><span class="line">    a3.sources.r3.spoolDir = /opt/module/flume/upload</span><br><span class="line">    a3.sources.r3.fileSuffix = .COMPLETED # 定义文件上传完的后缀</span><br><span class="line">    a3.sources.r3.fileHeader = true</span><br><span class="line">    # 忽略所有以.tmp 结尾的文件，不上传</span><br><span class="line">    a3.sources.r3.ignorePattern = ([^ ]*\.tmp)</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a3.sinks.k3.type = hdfs</span><br><span class="line">    a3.sinks.k3.hdfs.path = hdfs://hadoop102:9000/flume/upload/%Y%m%d/%H</span><br><span class="line">    # 上传文件的前缀</span><br><span class="line">    a3.sinks.k3.hdfs.filePrefix = upload-</span><br><span class="line">    # 是否按照时间滚动文件夹</span><br><span class="line">    a3.sinks.k3.hdfs.round = true</span><br><span class="line">    # 多少时间单位创建一个新的文件夹</span><br><span class="line">    a3.sinks.k3.hdfs.roundValue = 1</span><br><span class="line">    # 重新定义时间单位</span><br><span class="line">    a3.sinks.k3.hdfs.roundUnit = hour</span><br><span class="line">    # 是否使用本地时间戳</span><br><span class="line">    a3.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line">    # 积攒多少个 Event 才 flush 到 HDFS 一次</span><br><span class="line">    a3.sinks.k3.hdfs.batchSize = 100</span><br><span class="line">    # 设置文件类型，可支持压缩</span><br><span class="line">    a3.sinks.k3.hdfs.fileType = DataStream</span><br><span class="line">    # 多久生成一个新的文件</span><br><span class="line">    a3.sinks.k3.hdfs.rollInterval = 60</span><br><span class="line">    # 设置每个文件的滚动大小大概是 128M</span><br><span class="line">    a3.sinks.k3.hdfs.rollSize = 134217700</span><br><span class="line">    # 文件的滚动与 Event 数量无关</span><br><span class="line">    a3.sinks.k3.hdfs.rollCount = 0</span><br><span class="line">    # Use a channel which buffers events in memory</span><br><span class="line">    a3.channels.c3.type = memory</span><br><span class="line">    a3.channels.c3.capacity = 1000</span><br><span class="line">    a3.channels.c3.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a3.sources.r3.channels = c3</span><br><span class="line">    a3.sinks.k3.channel = c3</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-dir-hdfs.conf</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Exec source 适用于监控一个实时追加的文件，但不能保证数据不丢失；Spooldir Source 能够保证数据不丢失，且能够实现断点续传，但延迟较高，不能实时监控；而 Taildir Source 既能够实现断点续传，又可以保证数据不丢失，还能够进行实时监控。</p>
</blockquote>
<h4 id="Taildir"><a href="#Taildir" class="headerlink" title="Taildir"></a>Taildir</h4><blockquote>
<p>使用 Flume 监听整个目录的实时追加文件，并上传至 HDFS。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">vim flume-taildir-hdfs.conf</span><br><span class="line">    a3.sources = r3</span><br><span class="line">    a3.sinks = k3</span><br><span class="line">    a3.channels = c3</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a3.sources.r3.type = TAILDIR</span><br><span class="line">    # 维护了一个 json 格式的 position File</span><br><span class="line">    # 其会定期的往 position File 中更新每个文件读取到的最新的位置，因此能够实现断点续传</span><br><span class="line">    a3.sources.r3.positionFile = /opt/module/flume/tail_dir.json</span><br><span class="line">    a3.sources.r3.filegroups = f1</span><br><span class="line">    a3.sources.r3.filegroups.f1 = /opt/module/flume/files/file.*</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a3.sinks.k3.type = hdfs</span><br><span class="line">    a3.sinks.k3.hdfs.path =</span><br><span class="line">    hdfs://hadoop102:9000/flume/upload/%Y%m%d/%H</span><br><span class="line">    # 上传文件的前缀</span><br><span class="line">    a3.sinks.k3.hdfs.filePrefix = upload-</span><br><span class="line">    # 是否按照时间滚动文件夹</span><br><span class="line">    a3.sinks.k3.hdfs.round = true</span><br><span class="line">    # 多少时间单位创建一个新的文件夹</span><br><span class="line">    a3.sinks.k3.hdfs.roundValue = 1</span><br><span class="line">    # 重新定义时间单位</span><br><span class="line">    a3.sinks.k3.hdfs.roundUnit = hour</span><br><span class="line">    # 是否使用本地时间戳</span><br><span class="line">    a3.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line">    # 积攒多少个 Event 才 flush 到 HDFS 一次</span><br><span class="line">    a3.sinks.k3.hdfs.batchSize = 100</span><br><span class="line">    # 设置文件类型，可支持压缩</span><br><span class="line">    a3.sinks.k3.hdfs.fileType = DataStream</span><br><span class="line">    # 多久生成一个新的文件</span><br><span class="line">    a3.sinks.k3.hdfs.rollInterval = 60</span><br><span class="line">    # 设置每个文件的滚动大小大概是 128M</span><br><span class="line">    a3.sinks.k3.hdfs.rollSize = 134217700</span><br><span class="line">    # 文件的滚动与 Event 数量无关</span><br><span class="line">    a3.sinks.k3.hdfs.rollCount = 0</span><br><span class="line">    # Use a channel which buffers events in memory</span><br><span class="line">    a3.channels.c3.type = memory</span><br><span class="line">    a3.channels.c3.capacity = 1000</span><br><span class="line">    a3.channels.c3.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a3.sources.r3.channels = c3</span><br><span class="line">    a3.sinks.k3.channel = c3</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-taildir-hdfs.conf</span><br></pre></td></tr></table></figure>

<h3 id="进阶特性"><a href="#进阶特性" class="headerlink" title="进阶特性"></a>进阶特性</h3><h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume03.png" alt=""></p>
<h4 id="内部原理"><a href="#内部原理" class="headerlink" title="内部原理"></a>内部原理</h4><p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume04.png" alt=""></p>
<p><strong>ChannelSelector</strong></p>
<p>ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型，分别是 Replicating（复制）和 Multiplexing（多路复用）。</p>
<p>ReplicatingSelector 会将同一个 Event 发往所有的 Channel，Multiplexing 会根据相应的原则，将不同的 Event 发往不同的 Channel。</p>
<p><strong>SinkProcessor</strong></p>
<p>SinkProcessor 共有三种类型，分别是 DefaultSinkProcessor、LoadBalancingSinkProcessor 和 FailoverSinkProcessor。</p>
<p>DefaultSinkProcessor 对应的是单个的 Sink ， LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 Sink Group，LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以实现故障转移的功能。</p>
<h4 id="拓扑结构"><a href="#拓扑结构" class="headerlink" title="拓扑结构"></a>拓扑结构</h4><p><strong>简单串联</strong></p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume05.png" alt=""></p>
<p>将多个 flume 顺序连接起来了，从最初的 source 开始到最终 sink 传送的目的存储系统。此模式不建议桥接过多的 flume 数量，flume 数量过多不仅会影响传输速率， 而且一旦传输过程中某个节点 flume 宕机，会影响整个传输系统。</p>
<p><strong>复制和多路复用</strong></p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume06.png" alt=""></p>
<p>Flume 支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个 channel 中，或者将不同数据分发到不同的 channel 中，sink 可以选择传送到不同的目的地。</p>
<p><strong>负载均衡和故障转移</strong></p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume07.png" alt=""></p>
<p>Flume支持使用将多个 sink 逻辑上分到一个 sink 组，sink 组配合不同的 SinkProcessor 可以实现负载均衡和错误恢复的功能。</p>
<p><strong>聚合</strong></p>
<p><img src="http://welab-wingo.gitee.io/image/2020/05/Flume/Flume08.png" alt=""></p>
<p>这种模式是我们最常见的，也非常实用，日常 web 应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用 flume 的这种组合方式能很好的解决这一问题，每台服务器部署一个 flume 采集日志，传送到一个集中收集日志的 flume，再由此 flume 上传到 hdfs、hive、hbase 等，进行日志分析。</p>
<h3 id="企业开发"><a href="#企业开发" class="headerlink" title="企业开发"></a>企业开发</h3><h4 id="复制和复用"><a href="#复制和复用" class="headerlink" title="复制和复用"></a>复制和复用</h4><blockquote>
<p>使用 Flume-1 监控文件变动，Flume-1 将变动内容传递给 Flume-2，Flume-2 负责存储到 HDFS。同时 Flume-1 将变动内容传递给 Flume-3，Flume-3 负责输出到 Local FileSystem。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">cd group1/</span><br><span class="line">mkdir flume3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 监控文件变动</span></span><br><span class="line">vim flume-file-flume.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a1.sources = r1</span><br><span class="line">    a1.sinks = k1 k2</span><br><span class="line">    a1.channels = c1 c2</span><br><span class="line">    # 将数据流复制给所有 channel</span><br><span class="line">    a1.sources.r1.selector.type = replicating</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a1.sources.r1.type = exec</span><br><span class="line">    a1.sources.r1.command = tail -F /opt/module/hive/logs/hive.log</span><br><span class="line">    a1.sources.r1.shell = /bin/bash -c</span><br><span class="line">    # Describe the sink</span><br><span class="line">    # sink 端的 avro 是一个数据发送者</span><br><span class="line">    a1.sinks.k1.type = avro</span><br><span class="line">    a1.sinks.k1.hostname = hadoop102</span><br><span class="line">    a1.sinks.k1.port = 4141</span><br><span class="line">    a1.sinks.k2.type = avro</span><br><span class="line">    a1.sinks.k2.hostname = hadoop102</span><br><span class="line">    a1.sinks.k2.port = 4142</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a1.channels.c1.type = memory</span><br><span class="line">    a1.channels.c1.capacity = 1000</span><br><span class="line">    a1.channels.c1.transactionCapacity = 100</span><br><span class="line">    a1.channels.c2.type = memory</span><br><span class="line">    a1.channels.c2.capacity = 1000</span><br><span class="line">    a1.channels.c2.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a1.sources.r1.channels = c1 c2</span><br><span class="line">    a1.sinks.k1.channel = c1</span><br><span class="line">    a1.sinks.k2.channel = c2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 负责存储到 HDFS</span></span><br><span class="line">vim flume-flume-hdfs.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a2.sources = r1</span><br><span class="line">    a2.sinks = k1</span><br><span class="line">    a2.channels = c1</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    # source 端的 avro 是一个数据接收服务</span><br><span class="line">    a2.sources.r1.type = avro</span><br><span class="line">    a2.sources.r1.bind = hadoop102</span><br><span class="line">    a2.sources.r1.port = 4141</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a2.sinks.k1.type = hdfs</span><br><span class="line">    a2.sinks.k1.hdfs.path = hdfs://hadoop102:9000/flume2/%Y%m%d/%H</span><br><span class="line">    # 上传文件的前缀</span><br><span class="line">    a2.sinks.k1.hdfs.filePrefix = flume2-</span><br><span class="line">    # 是否按照时间滚动文件夹</span><br><span class="line">    a2.sinks.k1.hdfs.round = true</span><br><span class="line">    # 多少时间单位创建一个新的文件夹</span><br><span class="line">    a2.sinks.k1.hdfs.roundValue = 1</span><br><span class="line">    # 重新定义时间单位</span><br><span class="line">    a2.sinks.k1.hdfs.roundUnit = hour</span><br><span class="line">    # 是否使用本地时间戳</span><br><span class="line">    a2.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line">    # 积攒多少个 Event 才 flush 到 HDFS 一次</span><br><span class="line">    a2.sinks.k1.hdfs.batchSize = 100</span><br><span class="line">    # 设置文件类型，可支持压缩</span><br><span class="line">    a2.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line">    # 多久生成一个新的文件</span><br><span class="line">    a2.sinks.k1.hdfs.rollInterval = 600</span><br><span class="line">    # 设置每个文件的滚动大小大概是 128M</span><br><span class="line">    a2.sinks.k1.hdfs.rollSize = 134217700</span><br><span class="line">    # 文件的滚动与 Event 数量无关</span><br><span class="line">    a2.sinks.k1.hdfs.rollCount = 0</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a2.channels.c1.type = memory</span><br><span class="line">    a2.channels.c1.capacity = 1000</span><br><span class="line">    a2.channels.c1.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a2.sources.r1.channels = c1</span><br><span class="line">    a2.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 保存到本地目录</span></span><br><span class="line">vim flume-flume-dir.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a3.sources = r1</span><br><span class="line">    a3.sinks = k1</span><br><span class="line">    a3.channels = c2</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a3.sources.r1.type = avro</span><br><span class="line">    a3.sources.r1.bind = hadoop102</span><br><span class="line">    a3.sources.r1.port = 4142</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a3.sinks.k1.type = file_roll</span><br><span class="line">    # 输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录。</span><br><span class="line">    a3.sinks.k1.sink.directory = /opt/module/data/flume3</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a3.channels.c2.type = memory</span><br><span class="line">    a3.channels.c2.capacity = 1000</span><br><span class="line">    a3.channels.c2.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a3.sources.r1.channels = c2</span><br><span class="line">    a3.sinks.k1.channel = c2</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group1/flume-flume-dir.conf</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group1/flume-flume-hdfs.conf</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group1/flume-file-flume.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 Hadoop 和 Hive，查看结果</span></span><br></pre></td></tr></table></figure>

<h4 id="均衡和转移"><a href="#均衡和转移" class="headerlink" title="均衡和转移"></a>均衡和转移</h4><blockquote>
<p>使用 Flume1 监控一个端口，其 sink 组中的 sink 分别对接 Flume2 和 Flume3，采用 FailoverSinkProcessor，实现故障转移的功能。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">cd group2/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 监听 nectcat 发送的数据</span></span><br><span class="line">vim flume-netcat-flume.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a1.sources = r1</span><br><span class="line">    a1.channels = c1</span><br><span class="line">    a1.sinkgroups = g1</span><br><span class="line">    a1.sinks = k1 k2</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a1.sources.r1.type = netcat</span><br><span class="line">    a1.sources.r1.bind = localhost</span><br><span class="line">    a1.sources.r1.port = 44444</span><br><span class="line">    # 失败重试</span><br><span class="line">    a1.sinkgroups.g1.processor.type = failover</span><br><span class="line">    a1.sinkgroups.g1.processor.priority.k1 = 5</span><br><span class="line">    a1.sinkgroups.g1.processor.priority.k2 = 10</span><br><span class="line">    a1.sinkgroups.g1.processor.maxpenalty = 10000</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a1.sinks.k1.type = avro</span><br><span class="line">    a1.sinks.k1.hostname = hadoop102</span><br><span class="line">    a1.sinks.k1.port = 4141</span><br><span class="line">    a1.sinks.k2.type = avro</span><br><span class="line">    a1.sinks.k2.hostname = hadoop102</span><br><span class="line">    a1.sinks.k2.port = 4142</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a1.channels.c1.type = memory</span><br><span class="line">    a1.channels.c1.capacity = 1000</span><br><span class="line">    a1.channels.c1.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a1.sources.r1.channels = c1</span><br><span class="line">    # 成组负载平衡或故障转移策略</span><br><span class="line">    a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">    a1.sinks.k1.channel = c1</span><br><span class="line">    a1.sinks.k2.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 控制台输出 1 号</span></span><br><span class="line">vim flume-flume-console1.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a2.sources = r1</span><br><span class="line">    a2.sinks = k1</span><br><span class="line">    a2.channels = c1</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a2.sources.r1.type = avro</span><br><span class="line">    a2.sources.r1.bind = hadoop102</span><br><span class="line">    a2.sources.r1.port = 4141</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a2.sinks.k1.type = logger</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a2.channels.c1.type = memory</span><br><span class="line">    a2.channels.c1.capacity = 1000</span><br><span class="line">    a2.channels.c1.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a2.sources.r1.channels = c1</span><br><span class="line">    a2.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 控制台输出 2 号</span></span><br><span class="line">vim flume-flume-console2.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a3.sources = r1</span><br><span class="line">    a3.sinks = k1</span><br><span class="line">    a3.channels = c2</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a3.sources.r1.type = avro</span><br><span class="line">    a3.sources.r1.bind = hadoop102</span><br><span class="line">    a3.sources.r1.port = 4142</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a3.sinks.k1.type = logger</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a3.channels.c2.type = memory</span><br><span class="line">    a3.channels.c2.capacity = 1000</span><br><span class="line">    a3.channels.c2.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a3.sources.r1.channels = c2</span><br><span class="line">    a3.sinks.k1.channel = c2</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 netcat 工具向本机的 44444 端口发送内容</span></span><br><span class="line">nc localhost 44444</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 Flume2 及 Flume3 的控制台打印日志 </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将 Flume2 <span class="built_in">kill</span>，观察 Flume3 的控制台打印情况</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 jps -ml 查看 Flume 进程。</span></span><br></pre></td></tr></table></figure>

<h4 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h4><blockquote>
<p>hadoop102 上的 Flume-1 监控文件 /opt/module/data/group.log，hadoop103 上的 Flume-2 监控某一个端口的数据流， Flume-1 与 Flume-2 将数据发送给 hadoop104 上的 Flume-3，Flume-3 将最终数据打印到控制台。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 分发程序</span></span><br><span class="line">xsync flume</span><br><span class="line"><span class="meta">#</span><span class="bash"> 各节点上创建配置文件目录</span></span><br><span class="line">mkdir group3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 Source 用于监控 hive.log 文件，配置 Sink 输出数据到下一级 Flume。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hadoop102 上编辑配置文件</span></span><br><span class="line">vim flume1-logger-flume.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a1.sources = r1</span><br><span class="line">    a1.sinks = k1</span><br><span class="line">    a1.channels = c1</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a1.sources.r1.type = exec</span><br><span class="line">    a1.sources.r1.command = tail -F /opt/module/group.log</span><br><span class="line">    a1.sources.r1.shell = /bin/bash -c</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a1.sinks.k1.type = avro</span><br><span class="line">    a1.sinks.k1.hostname = hadoop104</span><br><span class="line">    a1.sinks.k1.port = 4141</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a1.channels.c1.type = memory</span><br><span class="line">    a1.channels.c1.capacity = 1000</span><br><span class="line">    a1.channels.c1.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a1.sources.r1.channels = c1</span><br><span class="line">    a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 Source 监控端口 44444 数据流，配置 Sink 数据到下一级 Flume：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hadoop103 上编辑配置文件</span></span><br><span class="line">vim flume2-netcat-flume.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a2.sources = r1</span><br><span class="line">    a2.sinks = k1</span><br><span class="line">    a2.channels = c1</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a2.sources.r1.type = netcat</span><br><span class="line">    a2.sources.r1.bind = hadoop103</span><br><span class="line">    a2.sources.r1.port = 44444</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a2.sinks.k1.type = avro</span><br><span class="line">    a2.sinks.k1.hostname = hadoop104</span><br><span class="line">    a2.sinks.k1.port = 4141</span><br><span class="line">    # Use a channel which buffers events in memory</span><br><span class="line">    a2.channels.c1.type = memory</span><br><span class="line">    a2.channels.c1.capacity = 1000</span><br><span class="line">    a2.channels.c1.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a2.sources.r1.channels = c1</span><br><span class="line">    a2.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 <span class="built_in">source</span> 用于接收 flume1 与 flume2 发送过来的数据流，最终合并后 sink 到控制台。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hadoop104 上编辑配置文件</span></span><br><span class="line">touch flume3-flume-logger.conf</span><br><span class="line">vim flume3-flume-logger.conf</span><br><span class="line">    # Name the components on this agent</span><br><span class="line">    a3.sources = r1</span><br><span class="line">    a3.sinks = k1</span><br><span class="line">    a3.channels = c1</span><br><span class="line">    # Describe/configure the source</span><br><span class="line">    a3.sources.r1.type = avro</span><br><span class="line">    a3.sources.r1.bind = hadoop104</span><br><span class="line">    a3.sources.r1.port = 4141</span><br><span class="line">    # Describe the sink</span><br><span class="line">    a3.sinks.k1.type = logger</span><br><span class="line">    # Describe the channel</span><br><span class="line">    a3.channels.c1.type = memory</span><br><span class="line">    a3.channels.c1.capacity = 1000</span><br><span class="line">    a3.channels.c1.transactionCapacity = 100</span><br><span class="line">    # Bind the source and sink to the channel</span><br><span class="line">    a3.sources.r1.channels = c1</span><br><span class="line">    a3.sinks.k1.channel = c1</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group3/flume3-flume-logger.conf -Dflume.root.logger=INFO,console</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group3/flume1-logger-flume.conf</span><br><span class="line">bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group3/flume2-netcat-flume.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hadoop103 上向/opt/module 目录下的 group.log 追加内容 </span></span><br><span class="line">echo 'hello' &gt; group.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hadoop102 上向 44444 端口发送数据 </span></span><br><span class="line">telnet hadoop102 44444</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查 hadoop104 上数据</span></span><br></pre></td></tr></table></figure>

<h4 id="Interceptor"><a href="#Interceptor" class="headerlink" title="Interceptor"></a>Interceptor</h4><p>在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到 Flume 拓扑结构中的 Multiplexing 结构。</p>
<p>Multiplexing 的原理是根据 event 中 Header 的某个 key 的值，将不同的 event 发送到不同的 Channel 中，所以我们需要自定义一个 Interceptor，为不同类型的 event 的 Header 中的 key 赋予不同的值。</p>
<p>在该案例中，我们以端口数据模拟日志，以数字（单个）和字母（单个）模拟不同类型的日志，我们需要自定义 interceptor 区分数字和字母，将其分别发往不同的分析系统 （Channel）。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 打成 jar 包放在 lib 目录下</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] body = event.getBody();</span><br><span class="line">        <span class="keyword">if</span> (body[<span class="number">0</span>] &lt; <span class="string">'z'</span> &amp;&amp; body[<span class="number">0</span>] &gt; <span class="string">'a'</span>) &#123;</span><br><span class="line">            <span class="comment">// 头部添加 K-V 用于识别分发</span></span><br><span class="line">            event.getHeaders().put(<span class="string">"type"</span>, <span class="string">"letter"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (body[<span class="number">0</span>] &gt; <span class="string">'0'</span> &amp;&amp; body[<span class="number">0</span>] &lt; <span class="string">'9'</span>) &#123;</span><br><span class="line">            event.getHeaders().put(<span class="string">"type"</span>, <span class="string">"number"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; events)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Event event : events) &#123;</span><br><span class="line">            intercept(event);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> events;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> <span class="keyword">implements</span> <span class="title">Interceptor</span>.<span class="title">Builder</span> </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> CustomInterceptor();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>为 hadoop102 上的 Flume1 配置 1 个 netcat source，1 个 sink group（2 个 avro sink）， 并配置相应的 ChannelSelector 和 interceptor。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 全路径，并且用”$“符号分割加上自定义 Builder 的类名</span></span><br><span class="line">a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.CustomInterceptor$Builder</span><br><span class="line">a1.sources.r1.selector.type = multiplexing</span><br><span class="line">a1.sources.r1.selector.header = type</span><br><span class="line"><span class="meta">#</span><span class="bash"> 根据头部 value 进行通道的选择</span></span><br><span class="line">a1.sources.r1.selector.mapping.letter = c1</span><br><span class="line">a1.sources.r1.selector.mapping.number = c2</span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop103</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type=avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop104</span><br><span class="line">a1.sinks.k2.port = 4242</span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line">a1.channels.c2.capacity = 1000</span><br><span class="line">a1.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 为 hadoop103/104 上的 Flume3 配置一个 avro <span class="built_in">source</span> 和一个 logger sink</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 分别在 hadoop102，hadoop103，hadoop104 上启动 flume 进程，注意先后顺序</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hadoop102 使用 netcat 向 localhost:44444 发送字母和数字</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 观察 hadoop103 和 hadoop104 打印的日志</span></span><br></pre></td></tr></table></figure>

<h4 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h4><blockquote>
<p>使用 flume 接收数据，并给每条数据添加前缀，输出到控制台。前缀可从 flume 配置文件中配置。</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 打成 jar 包放在 lib 目录下</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySource</span> <span class="keyword">extends</span> <span class="title">AbstractSource</span> <span class="keyword">implements</span> <span class="title">Configurable</span>, <span class="title">PollableSource</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义配置文件将来要读取的字段</span></span><br><span class="line">    <span class="keyword">private</span> Long delay;</span><br><span class="line">    <span class="keyword">private</span> String field;</span><br><span class="line">    <span class="comment">// 初始化配置信息</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        delay = context.getLong(<span class="string">"delay"</span>);</span><br><span class="line">        field = context.getString(<span class="string">"field"</span>, <span class="string">"Hello!"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 创建事件头信息</span></span><br><span class="line">            HashMap&lt;String, String&gt; hearderMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">            <span class="comment">// 创建事件</span></span><br><span class="line">            SimpleEvent event = <span class="keyword">new</span> SimpleEvent();</span><br><span class="line">            <span class="comment">// 循环封装事件</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">                <span class="comment">// 给事件设置头信息</span></span><br><span class="line">                event.setHeaders(hearderMap);</span><br><span class="line">                <span class="comment">// 给事件设置内容</span></span><br><span class="line">                event.setBody((field + i).getBytes());</span><br><span class="line">                <span class="comment">// 将事件写入 channel</span></span><br><span class="line">                getChannelProcessor().processEvent(event);</span><br><span class="line">                Thread.sleep(delay);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Status.READY;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getBackOffSleepIncrement</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMaxBackOffSleepInterval</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = com.wingo.MySource</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自定义配置</span></span><br><span class="line">a1.sources.r1.delay = 1000</span><br><span class="line"><span class="meta">#</span><span class="bash">a1.sources.r1.field = wingo</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<h4 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h4><p>Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent。</p>
<p>Sink 是完全事务性的。在从 Channel 批量删除数据之前，每个 Sink 用 Channel 启动一个事务。批量事件一旦成功写出到存储系统或下一个 Flume Agent，Sink 就利用 Channel 提交事务。事务一旦被提交，该 Channel 从自己的内部缓冲区删除事件。</p>
<blockquote>
<p>使用 flume 接收数据，并在 Sink 端给每条数据添加前缀和后缀，输出到控制台。前后缀可在 flume 任务配置文件中配置。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 打成 jar 包放在 lib 目录下</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySink</span> <span class="keyword">extends</span> <span class="title">AbstractSink</span> <span class="keyword">implements</span> <span class="title">Configurable</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建 Logger 对象</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(AbstractSink<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="keyword">private</span> String prefix;</span><br><span class="line">    <span class="keyword">private</span> String suffix;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException </span>&#123;</span><br><span class="line">        <span class="comment">// 声明返回值状态信息</span></span><br><span class="line">        Status status;</span><br><span class="line">        <span class="comment">// 获取当前 Sink 绑定的 Channel</span></span><br><span class="line">        Channel ch = getChannel();</span><br><span class="line">        <span class="comment">// 获取事务</span></span><br><span class="line">        Transaction txn = ch.getTransaction();</span><br><span class="line">        <span class="comment">// 声明事件</span></span><br><span class="line">        Event event;</span><br><span class="line">        <span class="comment">// 开启事务</span></span><br><span class="line">        txn.begin();</span><br><span class="line">        <span class="comment">// 读取 Channel 中的事件，直到读取到事件结束循环</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            event = ch.take();</span><br><span class="line">            <span class="keyword">if</span> (event != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 处理事件（打印）</span></span><br><span class="line">            LOG.info(prefix + <span class="keyword">new</span> String(event.getBody()) + suffix);</span><br><span class="line">            <span class="comment">// 事务提交</span></span><br><span class="line">            txn.commit();</span><br><span class="line">            status = Status.READY;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 遇到异常，事务回滚</span></span><br><span class="line">            txn.rollback();</span><br><span class="line">            status = Status.BACKOFF;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 关闭事务</span></span><br><span class="line">            txn.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 读取配置文件内容，有默认值</span></span><br><span class="line">        prefix = context.getString(<span class="string">"prefix"</span>, <span class="string">"hello:"</span>);</span><br><span class="line">        <span class="comment">// 读取配置文件内容，无默认值</span></span><br><span class="line">        suffix = context.getString(<span class="string">"suffix"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = com.wingo.MySink</span><br><span class="line">a1.sinks.k1.suffix = :wingo</span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<h3 id="Ganglia-监控"><a href="#Ganglia-监控" class="headerlink" title="Ganglia 监控"></a>Ganglia 监控</h3><blockquote>
<p>大公司一般用平台组开发的监控服务，中小型公司用的比较多的是这个，了解即可。</p>
</blockquote>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2020-07-10T03:37:23.451Z" itemprop="dateUpdated">2020-07-10 11:37:23</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="Wingo">
            Wingo
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Flume/" rel="tag">Flume</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2020/05/20/%E5%90%8E%E5%8F%B0%E6%8A%80%E6%9C%AF/Spring%20%E5%AE%9E%E6%88%98%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">Spring 实战学习笔记</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2020/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE/Kafka/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Kafka</h4>
      </a>
    </div>
  
</nav>



    




















</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
            <span>得失从缘，心无增减</span>
        </p>
    </div> 
    <div class="bottom">
        <p><span>Wingo &copy; 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: false, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










</body>
</html>
