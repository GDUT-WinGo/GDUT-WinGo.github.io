<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Hive | Wingo&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Hive">
    <meta name="description" content="Hive 基本介绍及简单使用。">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive">
<meta property="og:url" content="http://yoursite.com/2020/04/28/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/index.html">
<meta property="og:site_name" content="Wingo&#39;s Blog">
<meta property="og:description" content="Hive 基本介绍及简单使用。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive01.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive02.png">
<meta property="og:image" content="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive03.png">
<meta property="article:published_time" content="2020-04-28T03:27:12.000Z">
<meta property="article:modified_time" content="2020-07-10T03:39:21.927Z">
<meta property="article:author" content="Wingo">
<meta property="article:tag" content="Hive">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive01.png">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Wingo</h5>
          <a href="mailto:1318263468@qq.com" title="1318263468@qq.com" class="mail">1318263468@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Hive</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Hive</h1>
        <h5 class="subtitle">
            
                <time datetime="2020-04-28T03:27:12.000Z" itemprop="datePublished" class="page-time">
  2020-04-28
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基本概念"><span class="post-toc-number">1.</span> <span class="post-toc-text">基本概念</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#HQL-VS-SQL"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">HQL VS SQL</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#安装配置"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">安装配置</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基本操作"><span class="post-toc-number">2.</span> <span class="post-toc-text">基本操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#文件导入"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">文件导入</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#MySQL-安装"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">MySQL 安装</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#元数据配置"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">元数据配置</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#交互命令"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">交互命令</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#属性配置"><span class="post-toc-number">3.</span> <span class="post-toc-text">属性配置</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#仓库路径"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">仓库路径</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#日志信息"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">日志信息</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#数据类型"><span class="post-toc-number">4.</span> <span class="post-toc-text">数据类型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#简单类型"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">简单类型</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#复杂类型"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">复杂类型</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#实例操作"><span class="post-toc-number">4.3.</span> <span class="post-toc-text">实例操作</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#类型转化"><span class="post-toc-number">4.4.</span> <span class="post-toc-text">类型转化</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#DDL"><span class="post-toc-number">5.</span> <span class="post-toc-text">DDL</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#库操作"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">库操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#创建"><span class="post-toc-number">5.1.1.</span> <span class="post-toc-text">创建</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#显示"><span class="post-toc-number">5.1.2.</span> <span class="post-toc-text">显示</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#修改"><span class="post-toc-number">5.1.3.</span> <span class="post-toc-text">修改</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#删除"><span class="post-toc-number">5.1.4.</span> <span class="post-toc-text">删除</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#表操作"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">表操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#表类型"><span class="post-toc-number">5.2.1.</span> <span class="post-toc-text">表类型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#内部表"><span class="post-toc-number">5.2.1.1.</span> <span class="post-toc-text">内部表</span></a></li><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#外部表"><span class="post-toc-number">5.2.1.2.</span> <span class="post-toc-text">外部表</span></a></li></ol></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#表转换"><span class="post-toc-number">5.2.2.</span> <span class="post-toc-text">表转换</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#分区表"><span class="post-toc-number">5.2.3.</span> <span class="post-toc-text">分区表</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#列信息"><span class="post-toc-number">5.3.</span> <span class="post-toc-text">列信息</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#删除表"><span class="post-toc-number">5.4.</span> <span class="post-toc-text">删除表</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#DML"><span class="post-toc-number">6.</span> <span class="post-toc-text">DML</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#数据导入"><span class="post-toc-number">6.1.</span> <span class="post-toc-text">数据导入</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#数据导出"><span class="post-toc-number">6.2.</span> <span class="post-toc-text">数据导出</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#清除表"><span class="post-toc-number">6.3.</span> <span class="post-toc-text">清除表</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#查询"><span class="post-toc-number">7.</span> <span class="post-toc-text">查询</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Where"><span class="post-toc-number">7.1.</span> <span class="post-toc-text">Where</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#分组"><span class="post-toc-number">7.2.</span> <span class="post-toc-text">分组</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Join"><span class="post-toc-number">7.3.</span> <span class="post-toc-text">Join</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#排序"><span class="post-toc-number">7.4.</span> <span class="post-toc-text">排序</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#全局排序"><span class="post-toc-number">7.4.1.</span> <span class="post-toc-text">全局排序</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#内部排序"><span class="post-toc-number">7.4.2.</span> <span class="post-toc-text">内部排序</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#分区排序"><span class="post-toc-number">7.4.3.</span> <span class="post-toc-text">分区排序</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#桶"><span class="post-toc-number">7.5.</span> <span class="post-toc-text">桶</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#分桶抽样查询"><span class="post-toc-number">7.5.1.</span> <span class="post-toc-text">分桶抽样查询</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#其它"><span class="post-toc-number">7.6.</span> <span class="post-toc-text">其它</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#空字段赋值"><span class="post-toc-number">7.6.1.</span> <span class="post-toc-text">空字段赋值</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#行转列"><span class="post-toc-number">7.6.2.</span> <span class="post-toc-text">行转列</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#列转行"><span class="post-toc-number">7.6.3.</span> <span class="post-toc-text">列转行</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#窗口函数"><span class="post-toc-number">7.6.4.</span> <span class="post-toc-text">窗口函数</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Rank"><span class="post-toc-number">7.6.5.</span> <span class="post-toc-text">Rank</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#函数"><span class="post-toc-number">8.</span> <span class="post-toc-text">函数</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#自定义函数"><span class="post-toc-number">8.1.</span> <span class="post-toc-text">自定义函数</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-大数据/Hive"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Hive</h1>
        <div class="post-meta">
            <time class="post-time" title="2020-04-28 11:27:12" datetime="2020-04-28T03:27:12.000Z"  itemprop="datePublished">2020-04-28</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>Hive 基本介绍及简单使用。</p>
<a id="more"></a>

<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。</p>
<blockquote>
<p>本质上是将 HQL 转化为 MapReduce 程序。</p>
</blockquote>
<p><img src="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive01.png" alt=""></p>
<blockquote>
<p>Hive 处理的数据存储在 HDFS；<br>Hive 分析数据底层的实现是 MapReduce；<br>执行程序运行在 Yarn 上</p>
</blockquote>
<h4 id="HQL-VS-SQL"><a href="#HQL-VS-SQL" class="headerlink" title="HQL VS SQL"></a>HQL VS SQL</h4><table>
<thead>
<tr>
<th></th>
<th>Hive</th>
<th>RDBMS</th>
</tr>
</thead>
<tbody><tr>
<td>查询语言</td>
<td>HQL</td>
<td>SQL</td>
</tr>
<tr>
<td>数据存储</td>
<td>HDFS</td>
<td>LOCAL FS</td>
</tr>
<tr>
<td>执行</td>
<td>MapReduce</td>
<td>Executor</td>
</tr>
<tr>
<td>执行延迟</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>处理数据规模</td>
<td>大</td>
<td>小</td>
</tr>
<tr>
<td>索引</td>
<td>位图索引</td>
<td>复杂索引</td>
</tr>
</tbody></table>
<p><img src="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive02.png" alt=""></p>
<p>用户接口 Client：<br>CLI（hive shell）、JDBC / ODBC（java 访问 hive）、WEBUI（浏览器访问 hive）。</p>
<p>元数据 Metastore：<br>元数据包括表名、表所属的数据（默认是 default）、表的拥有者、列 / 分区字段、表的类型（是否是外部表）、表的数据所在目录等；默认存储在自带的 derby 数据库中，推荐使用 MySQL 存储 Metastore。</p>
<p>Hadoop<br>使用 HDFS 进行存储，使用 MapReduce 进行计算。</p>
<p>驱动器 Driver<br>解析器 SQL Parser：将 SQL 字符串转换成抽象语法树 AST；<br>编译器 Physical Plan： 将 AST 编译生成逻辑执行计划；<br>优化器 Query Optimizer：对逻辑执行计划进行优化；<br>执行器 Execution：把逻辑执行计划转换成可以运行的物理计划。对于 Hive 来 说，就是 MR / Spark。</p>
<p><img src="http://welab-wingo.gitee.io/image/2020/04/Hive/Hive03.png" alt=""></p>
<p>Hive 通过给用户提供的一系列交互接口，接收到用户的指令（SQL），使用自己的 Driver， 结合元数据（MetaStore），将这些指令翻译成 MapReduce，提交到 Hadoop 中执行，最后，将执行返回的结果输出到用户交互接口。</p>
<h4 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hive 安装</span></span><br><span class="line">tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /opt/module/</span><br><span class="line">mv apache-hive-1.2.1-bin/ hive</span><br><span class="line">mv hive-env.sh.template hive-env.sh</span><br><span class="line">vi hive-env.sh</span><br><span class="line"><span class="meta">	#</span><span class="bash"> <span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> <span class="built_in">export</span> HIVE_CONF_DIR=/opt/module/hive/conf</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 hive 前必须启动集群</span></span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建目录</span></span><br><span class="line">bin/hadoop fs -mkdir -p /user/hive/warehouse</span><br><span class="line">bin/hadoop fs -chmod g+w /user/hive/warehouse</span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者直接在配置文件中关闭权限检查</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hdfs-site.xml --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入 hive shell</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show databases;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> use default;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show tables;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> create table student(id int, name string);</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show tables;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc student;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> insert into student values(1000,<span class="string">"ss"</span>);</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> select * from student;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> quit;</span></span><br></pre></td></tr></table></figure>

<h4 id="文件导入"><a href="#文件导入" class="headerlink" title="文件导入"></a>文件导入</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将 /opt/module/datas/student.txt 文件导入 hive 的 student(id int, name string) 表中</span></span><br><span class="line"></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> create table student(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="string">'\t'</span>;</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> load data <span class="built_in">local</span> inpath <span class="string">'/opt/module/datas/student.txt'</span> into table student;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>再打开一个客户端窗口启动 hive，会产生 java.sql.SQLException 异常。原因是，Metastore 默认存储在自带的 derby 数据库中，推荐使用 MySQL 存储 Metastore。</p>
</blockquote>
<h5 id="MySQL-安装"><a href="#MySQL-安装" class="headerlink" title="MySQL 安装"></a>MySQL 安装</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 检查环境</span></span><br><span class="line">rpm -qa|grep mysql</span><br><span class="line">rpm -e --nodeps</span><br><span class="line">unzip mysql-libs.zip</span><br><span class="line"><span class="meta">	#</span><span class="bash"> MySQL-client-5.6.24-1.el6.x86_64.rpm</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> mysql-connector-java-5.1.27.tar.gz 驱动包</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> MySQL-server-5.6.24-1.el6.x86_64.rpm</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装服务</span></span><br><span class="line">rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取随机密码</span></span><br><span class="line">cat /root/.mysql_secret</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查服务状态</span></span><br><span class="line">service mysql status</span><br><span class="line">service mysql start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装客户端</span></span><br><span class="line">rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 利用好随机密码进行登录</span></span><br><span class="line">mysql -uroot -pOEXaQuS8IWkG19Xs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改密码</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">SET PASSWORD=PASSWORD(<span class="string">'000000'</span>);</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改 user 表中的主机配置</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">show databases;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">use mysql;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">show tables;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">desc user;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">select User, Host, Password from user;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">update user <span class="built_in">set</span> host=<span class="string">'%'</span> <span class="built_in">where</span> host=<span class="string">'localhost'</span>;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">delete from user <span class="built_in">where</span> Host=<span class="string">'127.0.0.1'</span>;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">delete from user <span class="built_in">where</span> Host=<span class="string">'::1'</span>;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置生效</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">flush privileges;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash">quit;</span></span><br></pre></td></tr></table></figure>

<h5 id="元数据配置"><a href="#元数据配置" class="headerlink" title="元数据配置"></a>元数据配置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 拷贝所需驱动</span></span><br><span class="line">cp mysql-connector-java-5.1.27-bin.jar /opt/module/hive/lib/</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 在 /opt/module/hive/conf 目录下创建一个 hive-site.xml --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 拷贝官方文档的配置参数 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://[ip_address]:3306/metastore?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>查看 MySQL 数据库，显示增加了 metastore 数据库。</p>
</blockquote>
<h4 id="交互命令"><a href="#交互命令" class="headerlink" title="交互命令"></a>交互命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看帮助</span></span><br><span class="line">bin/hive -help</span><br><span class="line"><span class="meta">#</span><span class="bash"> 不进入 hive 的交互窗口执行 sql 语句</span></span><br><span class="line">bin/hive -e "select id from student;"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行脚本中 sql 语句</span></span><br><span class="line">bin/hive -f /opt/module/datas/hivef.sql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行脚本，并写出结果</span></span><br><span class="line">bin/hive -f /opt/module/datas/hivef.sql &gt; /opt/module/datas/hive_result.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hive cli 命令窗口中查看 hdfs 文件系统</span></span><br><span class="line"><span class="meta">hive(default)&gt;</span><span class="bash">dfs -ls /;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 hive cli 命令窗口中查看本地文件系统</span></span><br><span class="line"><span class="meta">hive(default)&gt;</span><span class="bash">! ls /opt/module/datas;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看在 hive 中输入的所有历史命令，用户家目录下</span></span><br><span class="line">cat .hivehistory</span><br></pre></td></tr></table></figure>

<h3 id="属性配置"><a href="#属性配置" class="headerlink" title="属性配置"></a>属性配置</h3><h4 id="仓库路径"><a href="#仓库路径" class="headerlink" title="仓库路径"></a>仓库路径</h4><p>Default 数据仓库的最原始位置是在 hdfs 上的：/user/hive/warehouse 路径下；</p>
<p>在仓库目录下，没有对默认的数据库 default 创建文件夹。如果某张表属于 default 数据库，直接在数据仓库目录下创建一个文件夹。 </p>
<p>改 default 数据仓库原始位置（将 hive-default.xml.template 如下配置信息拷贝到 hive-site.xml 文件中）</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 显示数据表头信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 显示当前数据库名称信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置同组用户有执行权限</span></span><br><span class="line">bin/hdfs dfs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure>

<h4 id="日志信息"><a href="#日志信息" class="headerlink" title="日志信息"></a>日志信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 方式一</span></span><br><span class="line">mv hive-log4j.properties.template hive-log4j.properties</span><br><span class="line">vi hive-log4j.properties</span><br><span class="line"><span class="meta">	#</span><span class="bash"> hive.log.dir=/opt/module/hive/logs</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 方式二，仅对本次 hive 启动有效</span></span><br><span class="line">bin/hive -hiveconf hive.log.dir=/opt/module/hive/logs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 方式三，仅对本次 hive 启动有效</span></span><br><span class="line">hive (default)&gt; set hive.log.dir=/opt/module/hive/logs;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看所有参数配置</span></span><br><span class="line">hive (default)&gt; set [某一参数]</span><br></pre></td></tr></table></figure>

<h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><h4 id="简单类型"><a href="#简单类型" class="headerlink" title="简单类型"></a>简单类型</h4><table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>boolean</td>
<td>true / false</td>
<td>TRUE</td>
</tr>
<tr>
<td>tinyint</td>
<td>1 字节的有符号整数</td>
<td>-128~127 1Y</td>
</tr>
<tr>
<td>smallint</td>
<td>2 个字节的有符号整数，-32768~32767</td>
<td>1S</td>
</tr>
<tr>
<td>int</td>
<td>4 个字节的带符号整数</td>
<td>1</td>
</tr>
<tr>
<td>bigint</td>
<td>8 字节带符号整数</td>
<td>1L</td>
</tr>
<tr>
<td>float</td>
<td>4 字节单精度浮点数</td>
<td>1.0</td>
</tr>
<tr>
<td>double</td>
<td>8 字节双精度浮点数</td>
<td>1.0</td>
</tr>
<tr>
<td>deicimal</td>
<td>任意精度的带符号小数</td>
<td>1.0</td>
</tr>
<tr>
<td>String</td>
<td>字符串，变长</td>
<td>“a”,’b’</td>
</tr>
<tr>
<td>varchar</td>
<td>变长字符串</td>
<td>“a”,’b’</td>
</tr>
<tr>
<td>char</td>
<td>固定长度字符串</td>
<td>“a”,’b’</td>
</tr>
<tr>
<td>binary</td>
<td>字节数组</td>
<td>无法表示</td>
</tr>
<tr>
<td>timestamp</td>
<td>时间戳，纳秒精度</td>
<td>122327493795</td>
</tr>
<tr>
<td>date</td>
<td>日期</td>
<td>‘2018-04-07’</td>
</tr>
</tbody></table>
<h4 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h4><table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>array</td>
<td>有序的的同类型的集合</td>
<td>array(1,2)</td>
</tr>
<tr>
<td>map</td>
<td>key-value，key 必须为原始类型，value 可以任意类型</td>
<td>map(‘a’,1,’b’,2)</td>
</tr>
<tr>
<td>struct</td>
<td>字段集合,类型可以不同</td>
<td>struct(‘1’,1,1.0), named_stract(‘col1’,’1’,’col2’,1,’clo3’,1.0)</td>
</tr>
</tbody></table>
<h4 id="实例操作"><a href="#实例操作" class="headerlink" title="实例操作"></a>实例操作</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"songsong"</span>,</span><br><span class="line">    <span class="attr">"friends"</span>: [<span class="string">"bingbing"</span> , <span class="string">"lili"</span>] , <span class="comment">// 列表 Array</span></span><br><span class="line">    <span class="attr">"children"</span>: &#123; <span class="comment">// 键值 Map</span></span><br><span class="line">        <span class="attr">"xiao song"</span>: <span class="number">18</span> ,</span><br><span class="line">        <span class="attr">"xiaoxiao song"</span>: <span class="number">19</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">"address"</span>: &#123; <span class="comment">// 结构 Struct,</span></span><br><span class="line">    <span class="attr">"street"</span>: <span class="string">"hui long guan"</span> ,</span><br><span class="line">    <span class="attr">"city"</span>: <span class="string">"beijing"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>基于上述数据结构，我们在 Hive 里创建对应的表，并导入数据。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing &#x2F;&#x2F; 第一条 JSON</span><br><span class="line">yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing &#x2F;&#x2F; 第二条 JSON</span><br></pre></td></tr></table></figure>

<blockquote>
<p>MAP，STRUCT 和 ARRAY 里的元素间关系都可以用同一个字符表示，这里用 “_”。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(</span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">    friends <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">    children <span class="keyword">map</span>&lt;<span class="keyword">string</span>, <span class="built_in">int</span>&gt;,</span><br><span class="line">    address <span class="keyword">struct</span>&lt;street:<span class="keyword">string</span>, city:<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'_'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span></span><br><span class="line"><span class="keyword">lines</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\n'</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 导入数据</span></span><br><span class="line">hive (default)&gt; load data local inpath ‘/opt/module/datas/test.txt’ into table test</span><br><span class="line"><span class="meta">#</span><span class="bash"> 访问三种集合列里的数据，以下分别是 ARRAY，MAP，STRUCT 的访问方式</span></span><br><span class="line">select friends[1],children['xiao song'],address.city from test where name="songsong";</span><br><span class="line">OK</span><br><span class="line">_c0 _c1 city</span><br><span class="line">lili 18 beijing</span><br><span class="line">Time taken: 0.076 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>

<h4 id="类型转化"><a href="#类型转化" class="headerlink" title="类型转化"></a>类型转化</h4><p>Hive 的原子数据类型是可以进行隐式转换的，类似于 Java 的类型转换，例如某表达式 使用 INT 类型，TINYINT 会自动转换为 INT 类型，但是 Hive 不会进行反向转化，例如， 某表达式使用 TINYINT 类型，INT 不会自动转换为 TINYINT 类型，它会返回错误，除非使用 CAST 操作。</p>
<p>隐式类型转换规则：</p>
<blockquote>
<p>任何整数类型都可以隐式地转换为一个范围更广的类型，如 TINYINT 可以转换成 INT，INT 可以转换成 BIGINT；<br>所有整数类型、FLOAT 和 STRING 类型都可以隐式地转换成 DOUBLE；<br>TINYINT、SMALLINT、INT 都可以转换为 FLOAT；<br>BOOLEAN 类型不可以转换为任何其它的类型。</p>
</blockquote>
<p>可以使用 CAST 操作显示进行数据类型转换</p>
<blockquote>
<p>例如 CAST(‘1’ AS INT) 将把字符串 ‘1’  转换成整数 1；如果强制类型转换失败，如执行 CAST(‘X’ AS INT)，表达式返回空值 NULL。</p>
</blockquote>
<h3 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h3><blockquote>
<p>Data Definition Language 数据定义。</p>
</blockquote>
<h4 id="库操作"><a href="#库操作" class="headerlink" title="库操作"></a>库操作</h4><h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><blockquote>
<p>创建一个数据库，数据库在 HDFS 上的默认存储路径是 /user/hive/warehouse/*.db</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create database if not exists db_hive;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定库存储路径</span></span><br><span class="line">create database db_hive location '/db_hive.db';</span><br></pre></td></tr></table></figure>

<h5 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 显示数据库信息</span></span><br><span class="line">desc database db_hive;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示数据库详细信息 extended</span></span><br><span class="line">desc database extended db_hive;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换当前数据库</span></span><br><span class="line">use db_hive;</span><br></pre></td></tr></table></figure>

<h5 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h5><p>用户可以使用 ALTER DATABASE 命令为某个数据库的 DBPROPERTIES 设置键-值对属性值，来描述这个数据库的属性信息。</p>
<blockquote>
<p>数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置。修改当前正在使用的数据库，要先退出使用.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter database db_hive set dbproperties(&#39;createtime&#39;&#x3D;&#39;20170830&#39;);</span><br></pre></td></tr></table></figure>

<h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 采用 <span class="keyword">if</span> exists 判断数据库是否存在</span></span><br><span class="line">drop database if exists [db_name];</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果数据库不为空，可以采用 cascade 命令强制删除</span></span><br><span class="line">drop database [db_name] cascade;</span><br></pre></td></tr></table></figure>

<h4 id="表操作"><a href="#表操作" class="headerlink" title="表操作"></a>表操作</h4><h5 id="表类型"><a href="#表类型" class="headerlink" title="表类型"></a>表类型</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name </span><br><span class="line">   [(col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">   [COMMENT table_comment] </span><br><span class="line">   [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">   [CLUSTERED BY (col_name, col_name, ...) </span><br><span class="line">   [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] </span><br><span class="line">   [ROW FORMAT row_format] </span><br><span class="line">   [STORED AS file_format] </span><br><span class="line">   [LOCATION hdfs_path]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重命名</span></span><br><span class="line">ALTER TABLE table_name RENAME TO new_table_name</span><br></pre></td></tr></table></figure>

<p>EXTERNAL 关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION）。</p>
<blockquote>
<p>Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。<br>在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p>
</blockquote>
<p>PARTITIONED 表示根据某一个 key （不在 create table 里面）对数据进行分区，体现在 HDFS 上就是 table 目录下有 n 个不同的分区文件夹（country=China,country=USA）。</p>
<p>CLUSTERED 对于每一个表（table）或者分区， Hive 可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive 也是针对某一列进行桶的组织。Hive 采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。</p>
<blockquote>
<p>获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。<br>使取样（sampling）更高效。</p>
</blockquote>
<p>ROW FORMAT 用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。SerDe 是 Serialize / Deserilize 的简称，目的是用于序列化和反序列化。</p>
<p>STORED AS 指定存储文件类型。常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、 RCFILE（列式存储格式文件） 如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩， 使用 STORED AS SEQUENCEFILE。</p>
<p>LOCATION 指定表在 HDFS 上的存储位置。</p>
<p>LIKE 允许用户复制现有的表结构，但是不复制数据。</p>
<h6 id="内部表"><a href="#内部表" class="headerlink" title="内部表"></a>内部表</h6><blockquote>
<p>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive 会（或多或少地）控制着数据的生命周期。Hive 默认情况下会将这些表的数据存储在由配置项 hive.metastore.warehouse.dir（例如，/user/hive/warehouse）所定义的目录的子目录下。当删除一个管理表时，Hive 也会删除这个表中数据。内部表不适合和其他工具共享数据。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建内部表</span></span><br><span class="line">create table if not exists student(</span><br><span class="line">id int, name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by '\t'</span><br><span class="line">stored as textfile</span><br><span class="line">location '/user/hive/warehouse/student';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 根据查询结果创建表（查询的结果会添加到新创建的表中）</span></span><br><span class="line">create table if not exists student01 as select id, name from student;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 根据已经存在的表结构创建表</span></span><br><span class="line">create table if not exists student02 like student;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询表的类型</span></span><br><span class="line">desc formatted student01</span><br></pre></td></tr></table></figure>

<h6 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h6><blockquote>
<p>因为表是外部表，所以 Hive 并非认为其完全拥有这份数据。删除该表并不会删除掉这 份数据，不过描述表的元数据信息会被删除掉。</p>
</blockquote>
<p>每天将收集到的网站日志定期流入 HDFS 文本文件。在外部表（原始日志表）的基础 上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过 SELECT+INSERT 进入内部表。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建外部表部门表</span></span><br><span class="line">create external table if not exists default.dept(</span><br><span class="line">    deptno int,</span><br><span class="line">    dname string,</span><br><span class="line">    loc int</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建外部表员工表</span></span><br><span class="line">create external table if not exists default.emp(</span><br><span class="line">    empno int,</span><br><span class="line">    ename string,</span><br><span class="line">    job string,</span><br><span class="line">    mgr int,</span><br><span class="line">    hiredate string,</span><br><span class="line">    sal double,</span><br><span class="line">    comm double,</span><br><span class="line">    deptno int</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询表结构</span></span><br><span class="line">hive (default)&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">dept</span><br><span class="line">emp</span><br><span class="line"><span class="meta">#</span><span class="bash"> 向外部表中导入数据</span></span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/dept.txt' into table default.dept;</span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/emp.txt' into table default.emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询结果</span></span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line">hive (default)&gt; select * from dept;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看表的类型</span></span><br><span class="line">hive (default)&gt; desc formatted dept;</span><br><span class="line">Table Type: EXTERNAL_TABLE</span><br></pre></td></tr></table></figure>

<h5 id="表转换"><a href="#表转换" class="headerlink" title="表转换"></a>表转换</h5><blockquote>
<p>只能用单引号，严格区分大小写，如果不是完全符合，那么只会添加 K V 而不生效。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询表的类型</span></span><br><span class="line">hive (default)&gt; desc formatted student;</span><br><span class="line">Table Type: MANAGED_TABLE</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改内部表 student 为外部表</span></span><br><span class="line">alter table student set tblproperties('EXTERNAL'='TRUE');</span><br><span class="line">hive (default)&gt; desc formatted student;</span><br><span class="line">Table Type: EXTERNAL_TABLE</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改外部表 student 为内部表</span></span><br><span class="line">alter table student set tblproperties('EXTERNAL'='FALSE');</span><br><span class="line">hive (default)&gt; desc formatted student;</span><br><span class="line">Table Type: MANAGED_TABLE</span><br></pre></td></tr></table></figure>

<h5 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h5><blockquote>
<p>分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p>
</blockquote>
<p>一级分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 引入分区表（需要根据日期对日志进行管理）</span></span><br><span class="line">/user/hive/warehouse/log_partition/20170702/20170702.log</span><br><span class="line">/user/hive/warehouse/log_partition/20170703/20170703.log</span><br><span class="line">/user/hive/warehouse/log_partition/20170704/20170704.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建分区表语法</span></span><br><span class="line">hive (default)&gt; create table dept_partition(</span><br><span class="line">	deptno int, dname string, loc string</span><br><span class="line">)</span><br><span class="line">partitioned by (month string)</span><br><span class="line">row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 分区域导入数据</span></span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/dept.txt' into table</span><br><span class="line">default.dept_partition partition(month='201709');</span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/dept.txt' into table</span><br><span class="line">default.dept_partition partition(month='201708');</span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/dept.txt' into table</span><br><span class="line">default.dept_partition partition(month='201707’);</span><br><span class="line"><span class="meta">#</span><span class="bash"> 单分区查询</span></span><br><span class="line">hive (default)&gt; select * from dept_partition where month='201709';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 多分区联合查询 union（排序） or <span class="keyword">in</span> 三种方式</span></span><br><span class="line">hive (default)&gt; select * from dept_partition where month='201709'</span><br><span class="line">union</span><br><span class="line">select * from dept_partition where month='201708'</span><br><span class="line">union</span><br><span class="line">select * from dept_partition where month='201707';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 增加分区</span></span><br><span class="line">hive (default)&gt; alter table dept_partition add partition(month='201706') ;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 同时创建多个分区 用空格分开</span></span><br><span class="line">hive (default)&gt; alter table dept_partition add partition(month='201705') partition(month='201704');</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除单个分区</span></span><br><span class="line">hive (default)&gt; alter table dept_partition drop partition (month='201704');</span><br><span class="line"><span class="meta">#</span><span class="bash"> 同时删除多个分区 用逗号分开</span></span><br><span class="line">hive (default)&gt; alter table dept_partition drop partition (month='201705'), partition (month='201706');</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看分区表有多少分区</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show partitions dept_partition;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看分区表结构</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc formatted dept_partition;</span></span><br><span class="line">    # Partition Information</span><br><span class="line">    # col_name data_type </span><br><span class="line">    # comment month string</span><br></pre></td></tr></table></figure>

<p>二级分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建二级分区表</span></span><br><span class="line">hive (default)&gt; create table dept_partition2(</span><br><span class="line">	deptno int, dname string, loc string</span><br><span class="line">)</span><br><span class="line">partitioned by (month string, day string)</span><br><span class="line">row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载数据到二级分区表中</span></span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/dept.txt' into table default.dept_partition2 partition(month='201709', day='13');</span><br><span class="line">hive (default)&gt; select * from dept_partition2 where month='201709' and day='13';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 方式一：上传数据后修复</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传数据</span></span><br><span class="line">hive (default)&gt; dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=12;</span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/dept.txt /user/hive/warehouse/dept_partition2/month=201709/day=12; </span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询数据（查询不到刚上传的数据）</span></span><br><span class="line">hive (default)&gt; select * from dept_partition2 where month='201709' and day='12'; </span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行修复命令</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> msck repair table dept_partition2; </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次查询数据</span></span><br><span class="line">hive (default)&gt; select * from dept_partition2 where month='201709' and day='12';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 方式二：上传数据后添加分区</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传数据</span></span><br><span class="line">hive (default)&gt; dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=11;</span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/dept.txt /user/hive/warehouse/dept_partition2/month=201709/day=11; </span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行添加分区</span></span><br><span class="line">hive (default)&gt; alter table dept_partition2 add partition(month='201709',day='11'); </span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询数据</span></span><br><span class="line">hive (default)&gt; select * from dept_partition2 where month='201709' and day='11';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 方式三：上传数据后 load 数据到分区</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建目录</span></span><br><span class="line">hive (default)&gt; dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=10; </span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传数据</span></span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/dept.txt' into table dept_partition2 partition(month='201709',day='10');</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询数据</span></span><br><span class="line">hive (default)&gt; select * from dept_partition2 where month='201709' and day='10';</span><br></pre></td></tr></table></figure>

<h4 id="列信息"><a href="#列信息" class="headerlink" title="列信息"></a>列信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 更新列</span></span><br><span class="line">ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</span><br><span class="line">ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br><span class="line"><span class="meta">#</span><span class="bash"> ADD 是代表新增一字段，字段位置在所有列后面（partition 列前），REPLACE 则是表示替换表中所有字段</span></span><br></pre></td></tr></table></figure>

<h4 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; drop table [table_name];</span><br></pre></td></tr></table></figure>

<h3 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h3><h4 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一张表</span></span><br><span class="line">hive (default)&gt; create table student(id string, name string) row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载本地文件到 hive</span></span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/student.txt' into table default.student;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载 HDFS 文件到 hive 中</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传文件到 HDFS</span></span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /user/atguigu/hive;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载 HDFS 上的数据</span></span><br><span class="line">hive (default)&gt; load data inpath '/user/atguigu/hive/student.txt' into table default.student;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>加载数据覆盖表中已有的数据。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 上传文件到 HDFS</span></span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /user/atguigu/hive;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载数据覆盖表中已有的数据</span></span><br><span class="line">hive (default)&gt; load data inpath '/user/atguigu/hive/student.txt' overwrite into table default.student;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过查询语句向表中插入数据（Insert）。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一张分区表</span></span><br><span class="line">hive (default)&gt; create table student(id int, name string) partitioned by (month string) row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 基本插入数据</span></span><br><span class="line">hive (default)&gt; insert into table student partition(month='201709') values(1,'wangwu');</span><br><span class="line"><span class="meta">#</span><span class="bash"> 基本模式插入（根据单张表查询结果）</span></span><br><span class="line">hive (default)&gt; insert overwrite table student partition(month='201708') </span><br><span class="line">	select id, name from student where month='201709';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 多插入模式（根据多张表查询结果）</span></span><br><span class="line">hive (default)&gt; from student</span><br><span class="line">	insert overwrite table student partition(month='201707')</span><br><span class="line">	select id, name where month='201709'</span><br><span class="line">	insert overwrite table student partition(month='201706')</span><br><span class="line">	select id, name where month='201709';</span><br></pre></td></tr></table></figure>

<blockquote>
<p>查询语句中创建表并加载数据（As Select）。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据查询结果创建表（查询的结果会添加到新创建的表中）</span></span><br><span class="line">create table if not exists student_new as select id, name from student;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>创建表时通过 Location 指定加载数据路径.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建表，并指定在 hdfs 上的位置</span></span><br><span class="line">hive (default)&gt; create table if not exists student(</span><br><span class="line">	id int, name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by '\t'</span><br><span class="line">location '/user/hive/warehouse/student';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传数据到 hdfs 上</span></span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /user/hive/warehouse/student;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询数据</span></span><br><span class="line">hive (default)&gt; select * from student;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Import 数据（export 到处的数据）到指定 Hive 表中。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; import table student partition(month='201709') from '/user/hive/warehouse/export/student';</span><br></pre></td></tr></table></figure>

<h4 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h4><blockquote>
<p>Insert 导出。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将查询的结果导出到本地</span></span><br><span class="line">hive (default)&gt; insert overwrite local directory '/opt/module/datas/export/student' select * from student;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将查询的结果格式化导出到本地</span></span><br><span class="line">hive (default)&gt; insert overwrite local directory '/opt/module/datas/export/student' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' select * from student;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将查询的结果导出到 HDFS 上（没有 <span class="built_in">local</span>）</span></span><br><span class="line">hive (default)&gt; insert overwrite directory '/user/wingo/student' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' select * from student;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Hadoop 命令导出到本地。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -get /user/hive/warehouse/student/month=201709/000000_0 /opt/module/datas/export/student.txt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Hive Shell 命令导出。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive -e 'select * from default.student;' &gt; /opt/module/datas/export/student.txt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Export 导出到 HDFS 上。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default) &gt;export table default.student to '/user/hive/warehouse/export/student';</span><br></pre></td></tr></table></figure>

<h4 id="清除表"><a href="#清除表" class="headerlink" title="清除表"></a>清除表</h4><blockquote>
<p>Truncate 只能删除管理表，不能删除外部表中数据。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; truncate table student;</span><br></pre></td></tr></table></figure>

<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><blockquote>
<p>基本查询</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 全表查询</span></span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 选择特定列查询</span></span><br><span class="line">hive (default)&gt; select empno, ename from emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 列别名</span></span><br><span class="line">hive (default)&gt; select ename AS name, deptno dn from emp;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>运算符查询</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 算术运算符：查询出所有员工的薪水后加 1 显示</span></span><br><span class="line">hive (default)&gt; select sal+1 from emp;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>函数查询</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 求总行数（count）</span></span><br><span class="line">hive (default)&gt; select count(*) cnt from emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 求工资的最大值（max）</span></span><br><span class="line">hive (default)&gt; select max(sal) max_sal from emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 求工资的最小值（min）</span></span><br><span class="line">hive (default)&gt; select min(sal) min_sal from emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 求工资的总和（sum）</span></span><br><span class="line">hive (default)&gt; select sum(sal) sum_sal from emp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 求工资的平均值（avg）</span></span><br><span class="line">hive (default)&gt; select avg(sal) avg_sal from emp;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Limit 语句</p>
<p>典型的查询会返回多行数据。LIMIT 子句用于限制返回的行数。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp limit 5;</span><br></pre></td></tr></table></figure>

<h4 id="Where"><a href="#Where" class="headerlink" title="Where"></a>Where</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询出薪水大于 1000 的所有员工</span></span><br><span class="line">hive (default)&gt; select * from emp where sal &gt;1000;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>比较运算符（Between/In/ Is Null），这些操作符同样可以用于 JOIN…ON 和 HAVING 语句中。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询出薪水等于 5000 的所有员工</span></span><br><span class="line">hive (default)&gt; select * from emp where sal =5000;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询工资在 500 到 1000 的员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where sal between 500 and 1000;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询 comm 为空的所有员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where comm is null;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询工资是 1500 和 5000 的员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where sal IN (1500, 5000);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Like 和 RLike</p>
<p>% 代表零个或多个字符（任意个字符）；_ 代表一个字符<br>RLIKE 子句是 Hive 中这个功能的一个扩展，其可以通过 Java 的正则表达式这个更强大的语言来指定匹配条件。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查找以 2 开头薪水的员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where sal LIKE '2%';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查找第二个数值为 2 的薪水的员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where sal LIKE '_2%';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查找薪水中含有 2 的员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where sal RLIKE '[2]';</span><br></pre></td></tr></table></figure>

<blockquote>
<p>逻辑运算符（And/Or/Not）</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询薪水大于 1000，部门是 30</span></span><br><span class="line">hive (default)&gt; select * from emp where sal&gt;1000 and deptno=30;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询薪水大于 1000，或者部门是 30</span></span><br><span class="line">hive (default)&gt; select * from emp where sal&gt;1000 or deptno=30;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询除了 20 部门和 30 部门以外的员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp where deptno not IN(30, 20);</span><br></pre></td></tr></table></figure>

<h4 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h4><blockquote>
<p>GROUP BY 语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 计算 emp 表每个部门的平均工资</span></span><br><span class="line">hive (default)&gt; select t.deptno, avg(t.sal) avg_sal from emp t group by t.deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 计算 emp 每个部门中每个岗位的最高薪水</span></span><br><span class="line">hive (default)&gt; select t.deptno, t.job, max(t.sal) max_sal from emp t group by t.deptno, t.job;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Having 语句</p>
<p>where 针对表中的列发挥作用，查询数据；Having 针对查询结果中的列发挥作用， 筛选数据。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 求每个部门的平均薪水大于 2000 的部门</span></span><br><span class="line">hive (default)&gt; select deptno, avg(sal) avg_sal from emp group by deptno having avg_sal &gt; 2000;</span><br></pre></td></tr></table></figure>

<h4 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h4><blockquote>
<p>是只支持等值连接，不支持非等值连接</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门编号；</span></span><br><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno, d.dname from emp e join dept d on e.deptno = d.deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 合并员工表和部门表</span></span><br><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</span></span><br><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 左外连接：JOIN 操作符左边表中符合 WHERE 子句的所有记录将会被返回。</span></span><br><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e left join dept d on e.deptno = d.deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 右外连接：JOIN 操作符右边表中符合 WHERE 子句的所有记录将会被返回。</span></span><br><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e right join dept d on e.deptno = d.deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 满外连接：将会返回所有表中符合 WHERE 语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用 NULL 值替代。</span></span><br><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e full join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>多表连接，大多数情况下，Hive 会对每对 JOIN 连接对象启动一个 MapReduce 任务。Hive 总是按照从左到右的 顺序执行的。</p>
</blockquote>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><h5 id="全局排序"><a href="#全局排序" class="headerlink" title="全局排序"></a>全局排序</h5><blockquote>
<p>Order By：全局排序，一个 MapReduce。</p>
<p>ASC（ascend）: 升序（默认）；DESC（descend）: 降序。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询员工信息按工资升序排列</span></span><br><span class="line">hive (default)&gt; select * from emp order by sal;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询员工信息按工资降序排列</span></span><br><span class="line">hive (default)&gt; select * from emp order by sal desc;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按照别名排序，按照员工薪水的 2 倍排序</span></span><br><span class="line">hive (default)&gt; select ename, sal*2 twosal from emp order by twosal;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按照部门和工资升序排序</span></span><br><span class="line">hive (default)&gt; select ename, deptno, sal from emp order by deptno, sal ;</span><br></pre></td></tr></table></figure>

<h5 id="内部排序"><a href="#内部排序" class="headerlink" title="内部排序"></a>内部排序</h5><blockquote>
<p>每个 MapReduce 内部排序（Sort By）。</p>
<p>Sort By：每个 MapReduce 内部进行排序，对全局结果集来说不是排序。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置 reduce 个数</span></span><br><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看设置 reduce 个数</span></span><br><span class="line">hive (default)&gt; set mapreduce.job.reduces;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 根据部门编号降序查看员工信息</span></span><br><span class="line">hive (default)&gt; select * from emp sort by empno desc;</span><br><span class="line">hive (default)&gt; insert overwrite local directory '/opt/module/datas/sortby-result' select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure>

<h5 id="分区排序"><a href="#分区排序" class="headerlink" title="分区排序"></a>分区排序</h5><blockquote>
<p>Distribute By：类似 MR 中 partition，进行分区，结合 sort by 使用。</p>
<p>Hive 要求 DISTRIBUTE BY 语句要写在 SORT BY 语句之前</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 先按照部门编号分区，再按照员工编号降序排序。</span></span><br><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br><span class="line">hive (default)&gt; insert overwrite local directory '/opt/module/datas/distribute-result' </span><br><span class="line">	select * from emp distribute by deptno sort by empno desc;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Cluster By 除了具有 Distribute By 的功能外还兼具 Sort By 的功能。但是排序只能是倒序排序，不能指定排序规则为 ASC 或者 DESC。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 等价于</span></span><br><span class="line">hive (default)&gt; select * from emp distribute by deptno sort by deptno;</span><br></pre></td></tr></table></figure>

<h4 id="桶"><a href="#桶" class="headerlink" title="桶"></a>桶</h4><blockquote>
<p>分区针对的是数据的存储路径；分桶针对的是数据文件。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 第一次尝试</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建分桶表，按 id 取模</span></span><br><span class="line">create table stu_buck(id int, name string) </span><br><span class="line">	clustered by(id) </span><br><span class="line">	into 4 buckets </span><br><span class="line">	row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看表结构</span></span><br><span class="line">hive (default)&gt; desc formatted stu_buck;</span><br><span class="line"><span class="meta">	#</span><span class="bash"> Num Buckets: 4</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 导入数据到分桶表中，直接 load 不会进行分桶，还是一整个文件，那么通过 MR 导入呢？</span></span><br><span class="line">hive (default)&gt; load data local inpath '/opt/module/datas/student.txt' into table stu_buck;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 第二次尝试，创建分桶表时，数据通过子查询的方式导入</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建用于子查询的表</span></span><br><span class="line">create table stu(id int, name string)</span><br><span class="line">	row format delimited fields terminated by '\t';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 向普通的 stu 表中导入数据</span></span><br><span class="line">load data local inpath '/opt/module/datas/student.txt' into table stu;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 清空 stu_buck 表中数据</span></span><br><span class="line">truncate table stu_buck;</span><br><span class="line">select * from stu_buck;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 导入数据到分桶表，通过子查询的方式</span></span><br><span class="line">insert into table stu_buck select id, name from stu;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 发现还是只有一个分桶</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要设置一个属性</span></span><br><span class="line">hive (default)&gt; set hive.enforce.bucketing=true;</span><br><span class="line">hive (default)&gt; set mapreduce.job.reduces=-1;</span><br><span class="line">hive (default)&gt; insert into table stu_buck</span><br><span class="line">	select id, name from stu;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询分桶的数据，分桶成功</span></span><br><span class="line">hive (default)&gt; select * from stu_buck;</span><br></pre></td></tr></table></figure>

<h5 id="分桶抽样查询"><a href="#分桶抽样查询" class="headerlink" title="分桶抽样查询"></a>分桶抽样查询</h5><blockquote>
<p>对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结 果。Hive 可以通过对表进行抽样来满足这个需求。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询表 stu_buck 中的数据</span></span><br><span class="line">hive (default)&gt; select * from stu_buck tablesample (bucket 1 out of 4 on id);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>TABLESAMPLE(BUCKET x OUT OF y) </p>
<p>y 必须是 table 总 bucket 数的倍数或者因子。hive 根据 y 的大小，决定抽样的比例。<br>table 总 bucket 数为 4，tablesample(bucket 1 out of 2)，表示总共抽取（4/2=）2 个 bucket 的数据，抽取第  1(x) 个和第 4(x+y) 个 bucket 的数据。</p>
</blockquote>
<h4 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h4><h5 id="空字段赋值"><a href="#空字段赋值" class="headerlink" title="空字段赋值"></a>空字段赋值</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如果员工的 comm 为 NULL，则用-1 代替</span></span><br><span class="line">hive (default)&gt; select nvl(comm,-1) from emp;</span><br></pre></td></tr></table></figure>

<p>CASE WHEN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 求出不同部门男女各多少人</span></span><br><span class="line">vi emp_sex.txt</span><br><span class="line">    # 悟空 A 男</span><br><span class="line">    # 大海 A 男</span><br><span class="line">    # 宋宋 B 男</span><br><span class="line">    # 凤姐 A 女</span><br><span class="line">    # 婷姐 B 女</span><br><span class="line">    # 婷婷 B 女</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 hive 表并导入数据</span></span><br><span class="line">create table emp_sex(</span><br><span class="line">    name string,</span><br><span class="line">    dept_id int,</span><br><span class="line">    sex string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by "\t";</span><br><span class="line">load data local inpath '/opt/module/datas/emp_sex.txt' into table emp_sex;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按需求查询数据</span></span><br><span class="line">select </span><br><span class="line">	dept_id,</span><br><span class="line">	sum(case sex when '男' then 1 else 0 end) male_count,</span><br><span class="line">	sum(case sex when '女' then 1 else 0 end) female_count</span><br><span class="line">from</span><br><span class="line">	emp_sex</span><br><span class="line">group by</span><br><span class="line">	dept_id;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 结果</span></span><br><span class="line">    # A 2 1</span><br><span class="line">    # B 1 2</span><br></pre></td></tr></table></figure>

<h5 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h5><blockquote>
<p>CONCAT(string A/col, string B/col…)：返回输入字符串连接后的结果，支持任意个输入 字符串；</p>
<p>CONCAT_WS(separator, str1, str2,…)：它是一个特殊形式的 CONCAT()。第一个参数为参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL， 返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间；</p>
<p>COLLECT_SET(col)：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生 array 类型字段。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">vi constellation.txt</span><br><span class="line">    # 孙悟空 白羊座 A</span><br><span class="line">    # 大海 射手座 A</span><br><span class="line">    # 宋宋 白羊座 B</span><br><span class="line">    # 猪八戒 白羊座 A</span><br><span class="line">    # 凤姐 射手座 A</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按数据格式创建表</span></span><br><span class="line">create table person_info(</span><br><span class="line">    name string,</span><br><span class="line">    constellation string,</span><br><span class="line">    blood_type string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by "\t";</span><br><span class="line">load data local inpath “/opt/module/datas/person_info.txt” into table person_info;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按需求查询数据</span></span><br><span class="line">select</span><br><span class="line">	t1.base, concat_ws('|', collect_set(t1.name)) name</span><br><span class="line">from</span><br><span class="line">	(select</span><br><span class="line">		name,concat(constellation, ",", blood_type) base # 星座,血型</span><br><span class="line">	from</span><br><span class="line">		person_info</span><br><span class="line">	) t1</span><br><span class="line">group by</span><br><span class="line">	t1.base;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 结果</span></span><br><span class="line">    # 射手座,A 大海|凤姐</span><br><span class="line">    # 白羊座,A 孙悟空|猪八戒</span><br><span class="line">    # 白羊座,B 宋宋</span><br></pre></td></tr></table></figure>

<h5 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h5><blockquote>
<p>EXPLODE(col)：将 hive 一列中复杂的 array 或者 map 结构拆分成多行。 </p>
<p>LATERAL VIEW 用法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias<br>解释：与 split, explode 等 UDTF 一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建本地 movie.txt，导入数据</span></span><br><span class="line">vi movie.txt</span><br><span class="line">    # 《疑犯追踪》 悬疑,动作,科幻,剧情</span><br><span class="line">    # 《Lie to me》 悬疑,警匪,动作,心理,剧情</span><br><span class="line">    # 《战狼 2》 战争,动作,灾难</span><br><span class="line">create table movie_info(</span><br><span class="line">    movie string,</span><br><span class="line">    category array&lt;string&gt;</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by "\t"</span><br><span class="line">collection items terminated by ",";</span><br><span class="line">load data local inpath "/opt/module/datas/movie.txt" into table movie_info;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按需求查询数据</span></span><br><span class="line">select</span><br><span class="line">	movie,category_name</span><br><span class="line">from</span><br><span class="line">	movie_info </span><br><span class="line">lateral view </span><br><span class="line">	explode(category) table_tmp as category_name;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 结果</span></span><br><span class="line">    # 《疑犯追踪》 悬疑</span><br><span class="line">    # 《疑犯追踪》 动作</span><br><span class="line">    # 《疑犯追踪》 科幻</span><br><span class="line">    # 《疑犯追踪》 剧情</span><br><span class="line">    # 《Lie to me》 悬疑</span><br><span class="line">    # 《Lie to me》 警匪</span><br><span class="line">    # 《Lie to me》 动作</span><br><span class="line">    # 《Lie to me》 心理</span><br><span class="line">    # 《Lie to me》 剧情</span><br><span class="line">    # 《战狼 2》 战争</span><br><span class="line">    # 《战狼 2》 动作</span><br><span class="line">    # 《战狼 2》 灾难</span><br></pre></td></tr></table></figure>

<h5 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h5><blockquote>
<p>OVER()：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变而变化；<br>CURRENT ROW：当前行；<br>n PRECEDING：往前 n 行数据；<br>n FOLLOWING：往后 n 行数据；<br>UNBOUNDED：起点，UNBOUNDED PRECEDING 表示从前面的起点，UNBOUNDED FOLLOWING 表示到后面的终点；<br>LAG(col,n)：往前第 n 行数据<br>LEAD(col,n)：往后第 n 行数据<br>NTILE(n)：把有序分区中的行分发到指定数据的组中，各个组有编号，编号从 1 开始， 对于每一行，NTILE 返回此行所属的组的编号。注意：n 必须为 int 类型。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 数据准备</span></span><br><span class="line">name,orderdate,cost</span><br><span class="line">jack,2017-01-01,10</span><br><span class="line">tony,2017-01-02,15</span><br><span class="line">jack,2017-02-03,23</span><br><span class="line">tony,2017-01-04,29</span><br><span class="line">jack,2017-01-05,46</span><br><span class="line">jack,2017-04-06,42</span><br><span class="line">tony,2017-01-07,50</span><br><span class="line">jack,2017-01-08,55</span><br><span class="line">mart,2017-04-08,62</span><br><span class="line">mart,2017-04-09,68</span><br><span class="line">neil,2017-05-10,12</span><br><span class="line">mart,2017-04-11,75</span><br><span class="line">neil,2017-06-12,80</span><br><span class="line">mart,2017-04-13,94</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建本地 business.txt，导入数据</span></span><br><span class="line">vi business.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 hive 表并导入数据</span></span><br><span class="line">create table business(</span><br><span class="line">	name string,</span><br><span class="line">	orderdate</span><br><span class="line">	string,cost int</span><br><span class="line">) </span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';</span><br><span class="line">load data local inpath "/opt/module/datas/business.txt" into table business;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询在 2017 年 4 月份购买过的顾客及总人数</span></span><br><span class="line">select name,count(*) over() # group by 统计每一次条件下的数据；over() 开窗把整个数据即开给你用</span><br><span class="line">from business</span><br><span class="line">where substring(orderdate,1,7) = '2017-04'</span><br><span class="line">group by name;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询顾客的购买明细及月购买总额</span></span><br><span class="line">select name,orderdate,cost,sum(cost) over(partition by month(orderdate)) from business;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上述的场景,要将 cost 按照日期进行累加</span></span><br><span class="line">select name,orderdate,cost,</span><br><span class="line">sum(cost) over() as sample1,-- 所有行相加</span><br><span class="line">sum(cost) over(partition by name) as sample2,-- 按 name 分组，组内数据相加</span><br><span class="line">sum(cost) over(partition by name order by orderdate) as sample3,-- 按 name 分组，组内数据累加</span><br><span class="line">sum(cost) over(partition by name order by orderdate rows between UNBOUNDED PRECEDING</span><br><span class="line">and current row ) as sample4 ,-- 和 sample3 一样,由起点到当前行的聚合</span><br><span class="line">sum(cost) over(partition by name order by orderdate rows between 1 PRECEDING and current</span><br><span class="line">row) as sample5, -- 当前行和前面一行做聚合</span><br><span class="line">sum(cost) over(partition by name order by orderdate rows between 1 PRECEDING AND 1</span><br><span class="line">FOLLOWING ) as sample6,-- 当前行和前边一行及后面一行</span><br><span class="line">sum(cost) over(partition by name order by orderdate rows between current row and</span><br><span class="line">UNBOUNDED FOLLOWING ) as sample7 -- 当前行及后面所有行</span><br><span class="line">from business;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看顾客上次的购买时间</span></span><br><span class="line">select name,orderdate,cost,</span><br><span class="line">lag(orderdate,1,'1900-01-01') over(partition by name order by orderdate ) as time1,</span><br><span class="line">lag(orderdate,2) over (partition by name order by orderdate) as time2</span><br><span class="line">from business;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询前 20% 时间的订单信息</span></span><br><span class="line">select * from (</span><br><span class="line">select name,orderdate,cost, ntile(5) over(order by orderdate) sorted from business</span><br><span class="line">) t</span><br><span class="line">where sorted = 1;</span><br></pre></td></tr></table></figure>

<h5 id="Rank"><a href="#Rank" class="headerlink" title="Rank"></a>Rank</h5><blockquote>
<p>RANK() 排序相同时会重复，总数不会变；<br>DENSE_RANK()排序相同时会重复，总数会减少；<br>ROW_NUMBER() 会根据顺序计算。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">	name,</span><br><span class="line">	subject,</span><br><span class="line">	score,</span><br><span class="line">rank() over(partition by subject order by score desc) rp,</span><br><span class="line">dense_rank() over(partition by subject order by score desc) drp,</span><br><span class="line">row_number() over(partition by subject order by score desc) rmp</span><br><span class="line">from score;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 结果</span></span><br><span class="line">name subject score rp drp rmp</span><br><span class="line">宋宋 英语 84 1 1 1</span><br><span class="line">大海 英语 84 1 1 2</span><br><span class="line">婷婷 英语 78 3 2 3</span><br></pre></td></tr></table></figure>

<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看系统自带的函数</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show <span class="built_in">functions</span>;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示自带的函数的用法</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc <span class="keyword">function</span> upper;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 详细显示自带的函数的用法</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc <span class="keyword">function</span> extended upper;</span></span><br></pre></td></tr></table></figure>

<h4 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h4><p><a href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins" target="_blank" rel="noopener">官方文档地址</a></p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2020-07-10T03:39:21.927Z" itemprop="dateUpdated">2020-07-10 11:39:21</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="Wingo">
            Wingo
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2020/04/30/%E5%BC%80%E5%8F%91%E6%9D%82%E9%A1%B9/MySQL%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">MySQL 常用命令</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2020/04/26/%E5%BC%80%E5%8F%91%E6%9D%82%E9%A1%B9/Linux%20%E5%9F%BA%E7%A1%80/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Linux 基础</h4>
      </a>
    </div>
  
</nav>



    




















</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
            <span>得失从缘，心无增减</span>
        </p>
    </div> 
    <div class="bottom">
        <p><span>Wingo &copy; 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: false, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










</body>
</html>
